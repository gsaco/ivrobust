{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p> \ud83d\udd2c Research-Grade Econometrics </p> Get Started \u2192 User Guide API Reference <ol> <li> <p>Isaiah Andrews, James H. Stock, and Liyang Sun. Weak instruments in instrumental variables regression: theory and practice. Annual Review of Economics, 2019. doi:10.1146/annurev-economics-080218-025643.\u00a0\u21a9</p> </li> </ol>"},{"location":"#weak-iv-robust-inference-for-modern-econometrics","title":"Weak-IV Robust Inference for Modern Econometrics","text":"<p> A Python library implementing Anderson-Rubin, LM/K, and CLR tests with robust covariance options,  set-valued confidence sets, and comprehensive diagnostics. Built by researchers, for researchers. </p> Get Started API Reference View on GitHub \u2696\ufe0f Weak-IV Robust Valid inference under weak identification \ud83d\udcca Set-Valued CIs Disjoint and unbounded intervals supported \ud83d\udee1\ufe0f Robust Covariance HC0-HC3, clustering, and HAC options"},{"location":"#the-weak-instrument-problem","title":"The Weak Instrument Problem","text":"Figure 1: The identification challenge.  Strong instruments yield precise estimates (blue), while weak instruments create wide, unreliable confidence regions (coral).  ivrobust provides tests that remain valid regardless of instrument strength.  <p>Why this matters: Standard IV inference (2SLS t-tests) can be severely distorted when instruments are weak.  The Anderson-Rubin, LM, and CLR tests implemented in ivrobust maintain correct size even under weak identification, following the guidance of <sup>1</sup> and modern weak-IV econometrics.</p>"},{"location":"#core-methods","title":"Core Methods","text":"Figure 2: ivrobust methodology.  Three complementary approaches to weak-IV robust inference, each with distinct properties and use cases.  \u2696\ufe0f \ud83d\udcc8 \ud83d\udcca"},{"location":"#anderson-rubin-ar","title":"Anderson-Rubin (AR)","text":"<p>The foundational weak-IV robust test. Inverts the joint test on instruments  for confidence sets that are valid regardless of instrument strength.</p>  AR(\u03b2\u2080) = (Y - X\u03b2\u2080)'Pz(Y - X\u03b2\u2080) / s\u00b2  <p>\ud83d\udcda Anderson &amp; Rubin (1949)</p>"},{"location":"#lagrange-multiplier-lmk","title":"Lagrange Multiplier (LM/K)","text":"<p>Kleibergen's score-based test with optimal local power. Uses the score function  under the null hypothesis for efficient weak-IV robust inference.</p>  LM(\u03b2\u2080) = S(\u03b2\u2080)'\u03a9\u207b\u00b9S(\u03b2\u2080)  <p>\ud83d\udcda Kleibergen (2002)</p>"},{"location":"#conditional-likelihood-ratio-clr","title":"Conditional Likelihood Ratio (CLR)","text":"<p>Moreira's conditional test combining AR and LM statistics. Achieves near-optimal  power while maintaining weak-IV robustness through conditioning.</p>  CLR(\u03b2\u2080) = \u00bd(AR - rk + \u221a((AR - rk)\u00b2 + 4\u00b7LM\u00b7rk))  <p>\ud83d\udcda Moreira (2003)</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import ivrobust as ivr\n\n# Generate synthetic weak-IV data\ndata, beta_true = ivr.weak_iv_dgp(n=300, k=5, strength=0.4, beta=1.0, seed=0)\n\n# Run weak-IV robust inference\nres = ivr.weakiv_inference(\n    data,\n    beta0=beta_true,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n)\n\n# Access test results\nprint(f\"AR p-value: {res.tests['AR'].pvalue:.4f}\")\nprint(f\"CLR confidence set: {res.confidence_sets['CLR'].intervals}\")\n</code></pre> Full Quickstart Guide Interactive Notebooks"},{"location":"#practitioner-workflow","title":"Practitioner Workflow","text":"\ud83d\udcc1 \ud83d\udd0d \u2713 \ud83d\udcc8 <p>Complete Workflow Guide \u2192</p>"},{"location":"#1-prepare-data","title":"1. Prepare Data","text":"<p>Structure your IV model with IVData</p>"},{"location":"#2-diagnose","title":"2. Diagnose","text":"<p>Check instrument strength with diagnostics</p>"},{"location":"#3-test","title":"3. Test","text":"<p>Run AR/LM/CLR tests at your hypothesis</p>"},{"location":"#4-report","title":"4. Report","text":"<p>Generate publication-ready figures</p>"},{"location":"#gallery-highlights","title":"Gallery Highlights","text":"P-value curves across the parameter space. AR, LM, and CLR p-values showing where the null hypothesis is rejected.  Monte Carlo rejection rates. AR maintains correct size while 2SLS t-test over-rejects under weak instruments.  <p>View Full Gallery \u2192</p>"},{"location":"#research-team","title":"Research Team","text":"<p> ivrobust is developed and maintained by researchers committed to rigorous, reproducible econometric software. </p> GS +"},{"location":"#gabriel-saco","title":"Gabriel Saco","text":"<p>Lead Developer \u2022 Econometrics Research</p>"},{"location":"#contributors","title":"Contributors","text":"<p>Open source community</p>"},{"location":"#citing-ivrobust","title":"Citing ivrobust","text":"<p>\ud83d\udcc4 BibTeX</p> <pre><code>@software{ivrobust,\n  title = {ivrobust: Weak-IV Robust Inference in Python},\n  author = {Saco, Gabriel and contributors},\n  year = {2026},\n  url = {https://github.com/gsaco/ivrobust},\n  version = {0.2.0}\n}\n</code></pre> <p>When using ivrobust, please also cite the methodological references for the specific  tests you employ (see References).</p>"},{"location":"#trust-reproducibility","title":"Trust &amp; Reproducibility","text":"\ud83d\udd04 \ud83c\udfaf \ud83d\udcd6"},{"location":"#continuous-integration","title":"Continuous Integration","text":"<p>All commits are tested against a comprehensive suite including linting,  type checks, unit tests, notebook execution, and documentation builds.</p>"},{"location":"#reproducible-figures","title":"Reproducible Figures","text":"<p>Every figure in the documentation is generated from committed code with  fixed random seeds, ensuring full reproducibility.</p>"},{"location":"#clear-scope","title":"Clear Scope","text":"<p>Focused implementation of weak-IV robust inference for a single endogenous  regressor with comprehensive documentation and examples.</p>"},{"location":"diagnostics-interpretation/","title":"Diagnostics and interpretation","text":"<p>Weak-IV robust inference is only as good as the diagnostics you report. This page summarizes what ivrobust computes, how to interpret it, and which outputs are valid under weak identification.</p>"},{"location":"diagnostics-interpretation/#estimators-vs-tests-vs-confidence-sets","title":"Estimators vs tests vs confidence sets","text":"<ul> <li>Estimators (2SLS, LIML, Fuller) provide point estimates and standard   errors.</li> <li>Tests (AR, LM/K, CLR) remain valid under weak identification for a single   endogenous regressor.</li> <li>Confidence sets are obtained by inverting tests and can be disjoint or   unbounded.</li> </ul> <p>If instruments are weak, rely on the weak-IV robust tests and confidence sets rather than conventional t-tests from 2SLS.</p>"},{"location":"diagnostics-interpretation/#core-diagnostics-in-ivrobust","title":"Core diagnostics in ivrobust","text":"<pre><code>import ivrobust as ivr\n\ndiag = ivr.first_stage_diagnostics(data)\neff_f = ivr.effective_f(data, cov_type=\"HC1\")\nweak = ivr.weak_id_diagnostics(data, cov_type=\"HC1\")\nkp_rk = ivr.kp_rank_test(data, cov_type=\"HC1\")\n</code></pre> <p>How to read them</p> <ul> <li>First-stage F / partial R^2: Low values signal weak instruments. These are   convenient summaries, but they do not guarantee valid inference under weak ID.</li> <li>Effective F (Montiel Olea-Pflueger): A robust diagnostic intended for   heteroskedastic settings. Treat small values as a warning sign.   <sup>1</sup></li> <li>KP-rk test: Tests underidentification. A weak or insignificant result   suggests insufficient instrument relevance.</li> </ul>"},{"location":"diagnostics-interpretation/#safe-defaults","title":"Safe defaults","text":"<ul> <li>Use <code>weakiv_inference(..., methods=(\"AR\", \"LM\", \"CLR\"))</code> and report the full   set-valued confidence sets.</li> <li>For most workflows, use the package-wide default <code>cov_type=\"HC1\"</code> unless your   design requires clustering.</li> <li>When instrument strength is low, emphasize AR/LM/CLR results and use 2SLS   standard errors only for descriptive reporting.</li> </ul>"},{"location":"diagnostics-interpretation/#common-pitfalls","title":"Common pitfalls","text":"<ul> <li>Treating a narrow 2SLS interval as conclusive under weak instruments.</li> <li>Suppressing disjoint intervals instead of reporting the union of sets.</li> <li>Ignoring clustering when the data are clearly grouped.</li> </ul>"},{"location":"diagnostics-interpretation/#scope-reminders","title":"Scope reminders","text":"<p>ivrobust's weak-IV robust tests currently target a single endogenous regressor (<code>p_endog=1</code>). For multiple endogenous regressors, interpret results with care and consult the roadmap.</p> <ol> <li> <p>Jose Luis Montiel Olea and Carolin E. Pflueger. A robust test for weak instruments. Journal of Business &amp; Economic Statistics, 31(3):358\u2013369, 2013. doi:10.1080/00401706.2013.806694.\u00a0\u21a9</p> </li> </ol>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#why-is-my-confidence-set-disjoint-or-unbounded","title":"Why is my confidence set disjoint or unbounded?","text":"<p>This can occur under weak identification. In weak-IV robust inference, it is common that the identified set is wide or even effectively unbounded for plausible confidence levels.</p>"},{"location":"faq/#should-i-report-2sls-standard-errors","title":"Should I report 2SLS standard errors?","text":"<p>You can report them as conventional strong-ID standard errors, but they are not weak-IV robust. If instrument strength is questionable, report weak-IV robust inference (for example, an AR confidence set) alongside 2SLS estimates.</p>"},{"location":"gallery/","title":"Gallery","text":"<p> Publication-quality figures generated directly from ivrobust. Each visualization is reproducible  via committed code with fixed random seeds. </p> <p></p> Anderson-Rubin Confidence Set Set-valued confidence intervals from AR test inversion. The shaded region shows all parameter  values consistent with the data at the 95% level. Note that weak instruments can produce  disjoint or unbounded confidence sets.  \ud83d\udcc4 [PDF version](assets/figures/ar_confidence_set.pdf) \u2022  \ud83d\udcd3 [Source notebook](notebooks/00_quickstart/)  <p></p> P-Value Curves Across the Parameter Space AR, LM, and CLR p-values computed over a grid of hypothesized \u03b2 values. The horizontal line  at \u03b1 = 0.05 intersects each curve to define the corresponding confidence set boundaries.  \ud83d\udcc4 [PDF version](assets/figures/pvalue_curve.pdf) \u2022  \ud83d\udcd3 [Source notebook](https://github.com/gsaco/ivrobust/blob/main/notebooks/05_clr_in_practice.ipynb)  <p></p> Monte Carlo Size Comparison Rejection rates under the null hypothesis across varying instrument strength. The AR test  maintains correct size (near 5%) while the conventional 2SLS t-test severely over-rejects  when instruments are weak, confirming the importance of weak-IV robust methods.  \ud83d\udcc4 [PDF version](assets/figures/rejection_vs_strength.pdf) \u2022  \ud83d\udcd3 [Source notebook](https://github.com/gsaco/ivrobust/blob/main/notebooks/03_simulation_study.ipynb)  <p></p> Computational Performance Runtime scaling of the unified weak-IV workflow as a function of sample size and number of  instruments. The implementation remains efficient for typical empirical applications.  \ud83d\udcc4 [PDF version](assets/figures/runtime_scaling.pdf) \u2022  \ud83d\udcd3 [Source notebook](notebooks/08_runtime_scaling/)"},{"location":"gallery/#reproducibility","title":"Reproducibility","text":"<p>All figures in this gallery are generated by the following command:</p> <pre><code>python scripts/build_figures.py\n</code></pre> <p>Each script uses fixed random seeds to ensure exact reproducibility. The plotting style  is defined in <code>assets/ivrobust.mplstyle</code> and applied automatically via <code>ivr.set_style()</code>.</p> <p>Publication-Ready Output</p> <p>Use <code>ivr.savefig(fig, \"path/to/figure\", formats=(\"png\", \"pdf\"))</code> to export figures  in both raster and vector formats suitable for journal submission.</p>"},{"location":"how-to-cite/","title":"How to Cite","text":"<p>If you use ivrobust in academic research, please cite both the software and the  methodological references for the specific tests you employ.</p>"},{"location":"how-to-cite/#citing-ivrobust","title":"Citing ivrobust","text":"<p>\ud83d\udcc4 BibTeX</p> <pre><code>@software{ivrobust,\n  title     = {ivrobust: Weak-IV Robust Inference in Python},\n  author    = {Saco, Gabriel and contributors},\n  year      = {2026},\n  url       = {https://github.com/gsaco/ivrobust},\n  version   = {0.2.0},\n  note      = {Python package for Anderson-Rubin, LM, and CLR inference}\n}\n</code></pre> <p>\ud83d\udcdd APA Format</p> <pre><code>Saco, G., &amp; contributors. (2026). ivrobust: Weak-IV robust inference in Python \n(Version 0.2.0) [Computer software]. https://github.com/gsaco/ivrobust\n</code></pre>"},{"location":"how-to-cite/#methodological-references","title":"Methodological References","text":"<p>When reporting results from specific tests, please also cite the foundational papers:</p>"},{"location":"how-to-cite/#anderson-rubin-ar-test","title":"Anderson-Rubin (AR) Test","text":"<pre><code>@article{anderson1949,\n  title   = {Estimation of the Parameters of a Single Equation in a \n             Complete System of Stochastic Equations},\n  author  = {Anderson, T. W. and Rubin, Herman},\n  journal = {The Annals of Mathematical Statistics},\n  year    = {1949},\n  volume  = {20},\n  number  = {1},\n  pages   = {46--63}\n}\n</code></pre>"},{"location":"how-to-cite/#lmk-test-kleibergen","title":"LM/K Test (Kleibergen)","text":"<pre><code>@article{kleibergen2002,\n  title   = {Pivotal Statistics for Testing Structural Parameters in \n             Instrumental Variables Regression},\n  author  = {Kleibergen, Frank},\n  journal = {Econometrica},\n  year    = {2002},\n  volume  = {70},\n  number  = {5},\n  pages   = {1781--1803}\n}\n</code></pre>"},{"location":"how-to-cite/#clr-test-moreira","title":"CLR Test (Moreira)","text":"<pre><code>@article{moreira2003,\n  title   = {A Conditional Likelihood Ratio Test for Structural Models},\n  author  = {Moreira, Marcelo J.},\n  journal = {Econometrica},\n  year    = {2003},\n  volume  = {71},\n  number  = {4},\n  pages   = {1027--1048}\n}\n</code></pre>"},{"location":"how-to-cite/#example-acknowledgment","title":"Example Acknowledgment","text":"<p>We implement weak-IV robust inference using ivrobust (Saco et al., 2026),  which provides Anderson-Rubin (Anderson &amp; Rubin, 1949), LM (Kleibergen, 2002),  and CLR (Moreira, 2003) tests with heteroskedasticity-robust covariance estimation.</p>"},{"location":"how-to-cite/#citationcff","title":"CITATION.cff","text":"<p>ivrobust includes a machine-readable <code>CITATION.cff</code> file in the repository root.  GitHub and most reference managers can parse this format directly.</p> <p>View CITATION.cff on GitHub \u2192</p>"},{"location":"maintainers/","title":"Maintainer guide","text":"<p>This page summarizes the release and documentation workflow for ivrobust.</p>"},{"location":"maintainers/#install-docs-tooling","title":"Install docs tooling","text":"<pre><code>pip install -e \".[docs,plot,dev]\"\n</code></pre>"},{"location":"maintainers/#sync-notebooks-into-docs","title":"Sync notebooks into docs","text":"<pre><code>python scripts/sync_docs_notebooks.py\n</code></pre> <p>The curated notebook list lives inside the script. It copies <code>.ipynb</code> files and their artifacts into <code>docs-src/notebooks/</code>.</p>"},{"location":"maintainers/#build-docs-locally","title":"Build docs locally","text":"<pre><code>make docs\n</code></pre> <p>This runs the sync step and then executes <code>mkdocs build --strict</code>.</p>"},{"location":"maintainers/#update-figures","title":"Update figures","text":"<pre><code>make figures\n</code></pre> <p>Figures are saved under <code>docs-src/assets/figures/</code> and referenced in the gallery and homepage.</p>"},{"location":"maintainers/#run-notebooks","title":"Run notebooks","text":"<pre><code>pytest --nbmake notebooks/*.ipynb\n</code></pre> <p>Use <code>IVROBUST_MC_REPS</code> to scale Monte Carlo loops when needed.</p>"},{"location":"maintainers/#deploy-docs","title":"Deploy docs","text":"<p>Docs are deployed by GitHub Actions on pushes to <code>main</code> and tags:</p> <ul> <li>Workflow: <code>.github/workflows/release.yml</code></li> <li>Command: <code>mkdocs gh-deploy --force</code></li> </ul> <p>You can deploy locally with the same command if needed.</p>"},{"location":"notebooks/","title":"Notebooks","text":"<p>The notebook suite lives in <code>notebooks/</code> (paired <code>.ipynb</code> and <code>.py</code> via Jupytext). The documentation renders a curated subset inline and links to the full directory for additional materials.</p>"},{"location":"notebooks/#featured-notebooks-rendered-here","title":"Featured notebooks (rendered here)","text":"<ul> <li> <p> 00 Quickstart</p> <p>Weak instruments in 10 minutes. Unified API, confidence sets, and plots.</p> <p>Open notebook View source</p> </li> <li> <p> 01 Practitioner workflow (single endog)</p> <p>End-to-end applied workflow with AR/LM/CLR tests and confidence sets.</p> <p>Open notebook View source</p> </li> <li> <p> 02 Diagnostics and inference</p> <p>Effective F, weak-ID diagnostics, and interpretation guidance.</p> <p>Open notebook View source</p> </li> <li> <p> 04 Many instruments bias</p> <p>TSLS vs LIML vs Fuller bias and RMSE as k/n grows.</p> <p>Open notebook View source</p> </li> <li> <p> 04 Real data example</p> <p>Real-data IV workflow with robust inference and plots.</p> <p>Open notebook View source</p> </li> <li> <p> 08 Runtime scaling</p> <p>Lightweight runtime checks for grid inversion and inference.</p> <p>Open notebook View source</p> </li> </ul>"},{"location":"notebooks/#full-notebook-index","title":"Full notebook index","text":"<p>Additional notebooks (core API, CLR/LM in practice, robust covariance, and more) live in the repository:</p> <ul> <li>notebooks/ on GitHub</li> </ul> <p>Note</p> <p>Execute notebooks with <code>pytest --nbmake notebooks/*.ipynb</code>.</p>"},{"location":"parity/","title":"Parity and replication","text":"<p>ivrobust includes parity tests against reference implementations where available:</p> <ul> <li><code>tests/test_ar_vs_statsmodels.py</code> compares AR results to statsmodels.</li> <li><code>tests/test_lm_clr.py</code> compares LM/CLR to ivmodels when installed.</li> </ul> <p>Replication outputs are stored under <code>replication/outputs/</code> and validated by <code>tests/test_golden_replication.py</code>.</p>"},{"location":"parity/#feature-gap-map-stata-parity-benchmark","title":"Feature gap map (Stata parity benchmark)","text":"Category Status in ivrobust Evidence Stata expectation Notes AR test (scalar beta) Yes <code>src/ivrobust/weakiv/ar.py</code> AR test + CI by inversion Implemented with grid inversion. AR confidence set inversion Yes <code>src/ivrobust/intervals.py</code> Nonstandard CI shapes (empty/union/R) IntervalSet supports unions and unbounded sets. Kleibergen LM (score) Yes <code>src/ivrobust/weakiv/lm.py</code> LM/score tests with robust VCE Implemented as KP-LM for p_endog=1. CLR / CQLR Yes <code>src/ivrobust/weakiv/clr.py</code> CLR test + CI CQLR default; homoskedastic CLR available. Robust covariance (HC0-3) Yes <code>src/ivrobust/covariance.py</code> HC0-HC3 Supported across tests/estimators. Cluster-robust covariance Yes <code>src/ivrobust/covariance.py</code> One-way clustering Multiway clusters are combined, not CGM. HAC covariance Yes <code>src/ivrobust/covariance.py</code> Newey-West HAC lags and kernel supported. LIML / Fuller / k-class Yes <code>src/ivrobust/estimators/liml.py</code> LIML/Fuller estimators Provided for workflow estimates. Weak-IV diagnostics Yes <code>src/ivrobust/diagnostics/strength.py</code> Effective F, Stock-Yogo Effective F and partial Stock-Yogo table. Multiple endogenous regressors Not yet Roadmap Joint weak-IV inference Currently p_endog=1. Many-weak instruments CLR variants Not yet Roadmap Many-IV robust variants Planned; not implemented."},{"location":"quickstart/","title":"Quickstart","text":"<p>Get weak-IV robust inference in minutes with ivrobust.</p>"},{"location":"quickstart/#installation","title":"Installation","text":"With plotting support (recommended)Core onlyDevelopment <pre><code>pip install \"ivrobust[plot]\"\n</code></pre> <pre><code>pip install ivrobust\n</code></pre> <pre><code>git clone https://github.com/gsaco/ivrobust.git\ncd ivrobust\npip install -e \".[dev,plot]\"\n</code></pre>"},{"location":"quickstart/#your-first-analysis","title":"Your First Analysis","text":""},{"location":"quickstart/#step-1-prepare-your-data","title":"Step 1: Prepare Your Data","text":"<p>ivrobust uses an <code>IVData</code> container to structure your IV model:</p> <pre><code>import ivrobust as ivr\nimport numpy as np\n\n# Option A: Use built-in data generator for testing\ndata, beta_true = ivr.weak_iv_dgp(n=300, k=5, strength=0.4, beta=1.0, seed=0)\n\n# Option B: Create from your own arrays\n# data = ivr.IVData(Y=your_y, X=your_x, Z=your_z, W=your_controls)\n</code></pre>"},{"location":"quickstart/#step-2-run-weak-iv-robust-inference","title":"Step 2: Run Weak-IV Robust Inference","text":"<p>The unified workflow computes all three test statistics in one call:</p> <pre><code>res = ivr.weakiv_inference(\n    data,\n    beta0=beta_true,      # Null hypothesis value\n    alpha=0.05,           # Significance level\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",       # Heteroskedasticity-robust\n)\n</code></pre>"},{"location":"quickstart/#step-3-examine-results","title":"Step 3: Examine Results","text":"<pre><code># Test results\nprint(res.tests[\"AR\"].summary())\n# Output: AR statistic: 1.234, p-value: 0.267, df: 5\n\n# Confidence sets\nprint(res.confidence_sets[\"CLR\"].intervals)\n# Output: [(-0.42, 2.31)]  # Can be disjoint or unbounded!\n</code></pre>"},{"location":"quickstart/#visualization","title":"Visualization","text":""},{"location":"quickstart/#p-value-curves","title":"P-Value Curves","text":"<p>Visualize how p-values change across the parameter space:</p> <pre><code># Request grid computation\nres = ivr.weakiv_inference(\n    data,\n    beta0=beta_true,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n    grid=(beta_true - 2.0, beta_true + 2.0, 301),\n    return_grid=True,\n)\n\n# Generate publication-ready figure\nivr.set_style()\nfig, ax = res.plot()\nivr.savefig(fig, \"artifacts/pvalue_curve\", formats=(\"png\", \"pdf\"), dpi=300)\n</code></pre>"},{"location":"quickstart/#confidence-set-plots","title":"Confidence Set Plots","text":"<pre><code>cs = ivr.ar_confidence_set(data, alpha=0.05, cov_type=\"HC1\")\nfig, ax = ivr.plot_ar_confidence_set(cs)\nivr.savefig(fig, \"artifacts/ar_cs\", formats=(\"png\", \"pdf\"), dpi=300)\n</code></pre>"},{"location":"quickstart/#key-concepts","title":"Key Concepts","text":"\u26a0\ufe0f \ud83d\udcca \ud83d\udee1\ufe0f"},{"location":"quickstart/#why-not-just-use-2sls","title":"Why Not Just Use 2SLS?","text":"<p>Standard 2SLS t-tests can have severe size distortions when instruments are weak.  The AR/LM/CLR tests in ivrobust remain valid regardless of instrument strength.</p>"},{"location":"quickstart/#set-valued-confidence-sets","title":"Set-Valued Confidence Sets","text":"<p>Under weak identification, confidence sets may be disjoint (multiple intervals)  or unbounded (extending to \u00b1\u221e). ivrobust reports these directly without trimming.</p>"},{"location":"quickstart/#robust-covariance","title":"Robust Covariance","text":"<p>All tests support HC0-HC3 heteroskedasticity-robust and cluster-robust covariance  estimation via the <code>cov_type</code> parameter.</p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"[User Guide](user-guide/index.md){ .md-button .md-button--primary } [Choosing a Method](user-guide/choosing.md){ .md-button } [Interactive Notebooks](notebooks.md){ .md-button }   <p>For Practitioners</p> <p>See the Workflow Guide for a complete estimate \u2192 diagnose \u2192 test \u2192 report pipeline.</p>"},{"location":"references/","title":"References","text":"<p> The following references are foundational for weak-instrument robust inference  and the methods implemented in ivrobust. We encourage users to cite the relevant  methodological papers when reporting results. </p>"},{"location":"references/#core-methodological-papers","title":"Core Methodological Papers","text":"\ud83d\udcda \ud83d\udcda \ud83d\udcda"},{"location":"references/#anderson-rubin-1949","title":"Anderson &amp; Rubin (1949)","text":"<p>Estimation of the Parameters of a Single Equation in a Complete System of Stochastic Equations</p> <p>The Annals of Mathematical Statistics, 20(1), 46\u201363.</p> <p>The foundational paper introducing the Anderson-Rubin test for structural parameters in simultaneous equations models.</p> <p>DOI: 10.1214/aoms/1177730090</p>"},{"location":"references/#kleibergen-2002","title":"Kleibergen (2002)","text":"<p>Pivotal Statistics for Testing Structural Parameters in Instrumental Variables Regression</p> <p>Econometrica, 70(5), 1781\u20131803.</p> <p>Introduces the LM (K) statistic based on the score function, providing weak-IV robust inference with improved power properties.</p> <p>DOI: 10.1111/1468-0262.00353</p>"},{"location":"references/#moreira-2003","title":"Moreira (2003)","text":"<p>A Conditional Likelihood Ratio Test for Structural Models</p> <p>Econometrica, 71(4), 1027\u20131048.</p> <p>Develops the conditional likelihood ratio test that achieves near-optimal power while maintaining weak-IV robustness.</p> <p>DOI: 10.1111/1468-0262.00438</p>"},{"location":"references/#confidence-sets-and-diagnostics","title":"Confidence Sets and Diagnostics","text":"\ud83d\udcd0 \ud83d\udcca \ud83d\udd27"},{"location":"references/#mikusheva-2010","title":"Mikusheva (2010)","text":"<p>Robust Confidence Sets in the Presence of Weak Instruments</p> <p>Journal of Econometrics, 157(2), 236\u2013247.</p> <p>Theory for set-valued confidence sets under weak identification, including handling of disjoint and unbounded intervals.</p> <p>DOI: 10.1016/j.jeconom.2009.12.003</p>"},{"location":"references/#montiel-olea-pflueger-2013","title":"Montiel Olea &amp; Pflueger (2013)","text":"<p>A Robust Test for Weak Instruments</p> <p>Journal of Business &amp; Economic Statistics, 31(3), 358\u2013369.</p> <p>The effective F-statistic for heteroskedasticity-robust weak instrument diagnostics.</p> <p>DOI: 10.1080/00401706.2013.806694</p>"},{"location":"references/#stock-yogo-2005","title":"Stock &amp; Yogo (2005)","text":"<p>Testing for Weak Instruments in Linear IV Regression</p> <p>Identification and Inference for Econometric Models, Cambridge University Press, 80\u2013108.</p> <p>Critical values for weak instrument testing and guidelines for first-stage diagnostics.</p>"},{"location":"references/#implementations-and-reviews","title":"Implementations and Reviews","text":"\ud83d\udcbb \ud83d\udcd6"},{"location":"references/#finlay-magnusson-2009","title":"Finlay &amp; Magnusson (2009)","text":"<p>Implementing Weak-Instrument Robust Tests for a General Class of Instrumental-Variables Models</p> <p>The Stata Journal, 9(3), 398\u2013421.</p> <p>Practical implementation guidance and Stata commands for weak-IV robust inference.</p> <p>DOI: 10.1177/1536867X0900900304</p>"},{"location":"references/#andrews-stock-sun-2019","title":"Andrews, Stock &amp; Sun (2019)","text":"<p>Weak Instruments in Instrumental Variables Regression: Theory and Practice</p> <p>Annual Review of Economics, 11, 727\u2013753.</p> <p>Comprehensive modern review of weak instruments, recommended practices, and recent developments.</p> <p>DOI: 10.1146/annurev-economics-080218-025643</p>"},{"location":"references/#see-also","title":"See Also","text":"<ul> <li>How to Cite \u2014 BibTeX entries for citing ivrobust</li> <li>Methods at a Glance \u2014 Overview of implemented methods</li> </ul>"},{"location":"replication/","title":"Replication","text":"<p>This repository includes a lightweight replication harness under <code>replication/</code>.</p> <p>Contents</p> <ul> <li><code>replication/data/weak_iv_fixture.csv</code>: deterministic fixture used by golden tests.</li> <li><code>replication/outputs/golden.json</code>: committed reference outputs produced by ivrobust.</li> <li><code>replication/stata/ivreg2.do</code>: placeholder Stata script (ivreg2).</li> <li><code>replication/r/ivreg.R</code>: placeholder R script (AER::ivreg).</li> </ul> <p>Workflow</p> <ol> <li>Regenerate the golden outputs (Python):</li> </ol> <pre><code>python replication/generate_golden.py\n</code></pre> <ol> <li>Run Stata/R scripts to compare outputs against external packages.</li> <li>Replace <code>replication/outputs/golden.json</code> with verified results and re-run tests.</li> </ol> <p>Notes</p> <ul> <li>CI never runs Stata or R. The scripts are provided for reproducibility.</li> <li>The committed <code>golden.json</code> currently reflects ivrobust outputs on the fixture.</li> </ul>"},{"location":"reproducibility/","title":"Reproducibility","text":"<p>ivrobust is designed for reproducible, researcher-grade workflows. This page summarizes how the figures and notebooks in the documentation are generated.</p>"},{"location":"reproducibility/#seeds-and-determinism","title":"Seeds and determinism","text":"<ul> <li>Synthetic data in the docs use <code>weak_iv_dgp</code> with fixed random seeds.</li> <li>Figure generation scripts save both plots and cached data summaries.</li> <li>CI uses a fixed <code>PYTHONHASHSEED</code> to reduce non-determinism.</li> </ul>"},{"location":"reproducibility/#rebuild-figures","title":"Rebuild figures","text":"<pre><code>python scripts/build_figures.py\n</code></pre> <p>Figures are saved to <code>docs-src/assets/figures/</code> and cached data are stored in <code>docs-src/assets/data/</code> as <code>.npz</code> files.</p> <p>Using the Makefile shortcut:</p> <pre><code>make figures\n</code></pre>"},{"location":"reproducibility/#execute-notebooks","title":"Execute notebooks","text":"<pre><code>pytest --nbmake notebooks/*.ipynb\n</code></pre> <p>Notebooks are intentionally lightweight and use small sample sizes by default. Set environment variables or edit the notebook parameters if you need larger simulation sizes.</p>"},{"location":"reproducibility/#sync-notebooks-into-docs","title":"Sync notebooks into docs","text":"<pre><code>python scripts/sync_docs_notebooks.py\n</code></pre> <p>The docs render a curated subset of notebooks. This sync copies the selected <code>.ipynb</code> files plus their saved figures into <code>docs-src/notebooks/</code>.</p>"},{"location":"reproducibility/#build-documentation","title":"Build documentation","text":"<pre><code>mkdocs build --strict\n</code></pre> <p>The MkDocs source lives in <code>docs-src/</code> and the built site is committed to <code>docs/</code> for GitHub Pages branch-based deployment.</p> <p>Makefile shortcut:</p> <pre><code>make docs\n</code></pre> <p><code>make docs</code> runs <code>sync_docs_notebooks.py</code> first to ensure rendered notebooks and figures are up to date.</p>"},{"location":"reproducibility/#link-checking","title":"Link checking","text":"<pre><code>python scripts/check_links.py --site-dir docs\nmake links\n</code></pre>"},{"location":"roadmap/","title":"Roadmap","text":"<p>This roadmap distinguishes between:</p> <ul> <li>P0: required for a stable release (current scope)</li> <li>P1: next methods and diagnostics</li> <li>P2: extended method coverage and performance work</li> </ul>"},{"location":"roadmap/#p0-current","title":"P0 (current)","text":"<ul> <li>AR/LM/CLR tests and confidence sets for a scalar structural parameter.</li> <li>HC0/HC1/HC2/HC3, HAC, and one-way cluster-robust covariance options.</li> <li>Effective F diagnostics for weak instruments.</li> <li>Verified implementation against a reference regression engine.</li> </ul>"},{"location":"roadmap/#p1-next","title":"P1 (next)","text":"<ul> <li>Multi-endogenous support with scalar-target inference.</li> <li>Many-instrument diagnostics and optional many-IV adjustments.</li> </ul>"},{"location":"roadmap/#p2-extended","title":"P2 (extended)","text":"<ul> <li>Formula interface (optional dependency) for applied workflows.</li> <li>Performance improvements (QR-based projections, caching repeated   cross-products).</li> </ul>"},{"location":"methods/","title":"Methods at a glance","text":"<p>ivrobust focuses on weak-IV robust inference for a single endogenous regressor. Use the unified workflow when you want consistent defaults and comparable output across AR, LM/K, and CLR procedures.</p> <pre><code>import ivrobust as ivr\n\nres = ivr.weakiv_inference(data, beta0=1.0, methods=(\"AR\", \"LM\", \"CLR\"))\nres.tests.keys(), res.confidence_sets.keys()\n</code></pre>"},{"location":"methods/#core-tests-and-confidence-sets","title":"Core tests and confidence sets","text":"<ul> <li> <p>Anderson-Rubin (AR)</p> <p>Joint test on instruments under the null with weak-ID robustness. Invert the AR test for set-valued confidence intervals. <sup>1</sup><sup>2</sup></p> </li> <li> <p>LM/K test</p> <p>Kleibergen-Paap LM statistic with covariance choices matched to your application. <sup>3</sup></p> </li> <li> <p>CLR / CQLR</p> <p>Conditional likelihood ratio inference with grid inversion for confidence sets. <sup>4</sup></p> </li> </ul>"},{"location":"methods/#scope-and-assumptions","title":"Scope and assumptions","text":"<ul> <li>The weak-IV robust tests in ivrobust target one endogenous regressor   (<code>p_endog=1</code>).</li> <li>Confidence sets are produced by test inversion and can be disjoint or   unbounded; report the full union of intervals.</li> <li>Robust covariance options (HC0-HC3, clustering, HAC) apply across tests and   diagnostics.</li> </ul>"},{"location":"methods/#robust-covariance-and-diagnostics","title":"Robust covariance and diagnostics","text":"<ul> <li> <p>Robust covariance</p> <p>HC0-HC3 and one-way cluster robust options across tests and diagnostics. <sup>5</sup></p> </li> <li> <p>Set-valued confidence sets</p> <p>Disjoint, unbounded intervals are reported directly rather than trimmed. <sup>6</sup></p> </li> <li> <p>Diagnostics</p> <p>Effective F, KP-rk, and weak-ID diagnostics for instrument strength. <sup>7</sup></p> </li> </ul>"},{"location":"methods/#related-api-entrypoints","title":"Related API entrypoints","text":"<pre><code>ivr.ar_test(data, beta0=1.0)\nivr.lm_test(data, beta0=1.0)\nivr.clr_test(data, beta0=1.0)\n\nivr.ar_confidence_set(data, alpha=0.05)\nivr.lm_confidence_set(data, alpha=0.05)\nivr.clr_confidence_set(data, alpha=0.05)\n</code></pre> <p>See the User guide for method-specific details.</p> <ol> <li> <p>T. W. Anderson and Herman Rubin. Estimation of the parameters of a single equation in a complete system of stochastic equations. The Annals of Mathematical Statistics, 20(1):46\u201363, 1949. doi:10.1214/aoms/1177730090.\u00a0\u21a9</p> </li> <li> <p>Isaiah Andrews, James H. Stock, and Liyang Sun. Weak instruments in instrumental variables regression: theory and practice. Annual Review of Economics, 2019. doi:10.1146/annurev-economics-080218-025643.\u00a0\u21a9</p> </li> <li> <p>Frank Kleibergen. Pivotal statistics for testing structural parameters in instrumental variables regression. Econometrica, 70(5):1781\u20131803, 2002. doi:10.1111/1468-0262.00353.\u00a0\u21a9</p> </li> <li> <p>Marcelo J. Moreira. A conditional likelihood ratio test for structural models. Econometrica, 71(4):1027\u20131048, 2003. doi:10.1111/1468-0262.00438.\u00a0\u21a9</p> </li> <li> <p>Keith Finlay and Leandro M. Magnusson. Implementing weak-instrument robust tests for a general class of instrumental-variables models. The Stata Journal, 9(3):398\u2013421, 2009. doi:10.1177/1536867X0900900304.\u00a0\u21a9</p> </li> <li> <p>Anna Mikusheva. Robust confidence sets in the presence of weak instruments. Journal of Econometrics, 157(2):236\u2013247, 2010. doi:10.1016/j.jeconom.2009.12.003.\u00a0\u21a9</p> </li> <li> <p>Jose Luis Montiel Olea and Carolin E. Pflueger. A robust test for weak instruments. Journal of Business &amp; Economic Statistics, 31(3):358\u2013369, 2013. doi:10.1080/00401706.2013.806694.\u00a0\u21a9</p> </li> </ol>"},{"location":"notebooks/00_quickstart/","title":"ivrobust - Quickstart","text":"In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n\nimport ivrobust as ivr\n\nART = Path(\"artifacts\") / \"00_quickstart\"\nART.mkdir(parents=True, exist_ok=True)\n\nivr.set_style()\n</pre> from pathlib import Path  import ivrobust as ivr  ART = Path(\"artifacts\") / \"00_quickstart\" ART.mkdir(parents=True, exist_ok=True)  ivr.set_style() In\u00a0[\u00a0]: Copied! <pre>data, beta_true = ivr.weak_iv_dgp(n=300, k=5, strength=0.4, beta=1.0, seed=0)\nbeta_true\n</pre> data, beta_true = ivr.weak_iv_dgp(n=300, k=5, strength=0.4, beta=1.0, seed=0) beta_true In\u00a0[\u00a0]: Copied! <pre>res = ivr.weakiv_inference(\n    data,\n    beta0=beta_true,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n)\nres.tests[\"AR\"]\n</pre> res = ivr.weakiv_inference(     data,     beta0=beta_true,     alpha=0.05,     methods=(\"AR\", \"LM\", \"CLR\"),     cov_type=\"HC1\", ) res.tests[\"AR\"] In\u00a0[\u00a0]: Copied! <pre>cs = res.confidence_sets[\"AR\"]\ncs.confidence_set.intervals\n</pre> cs = res.confidence_sets[\"AR\"] cs.confidence_set.intervals In\u00a0[\u00a0]: Copied! <pre>fig, ax = ivr.plot_ar_confidence_set(cs)\nivr.savefig(fig, ART / \"ar_confidence_set\", formats=(\"png\", \"pdf\"))\n</pre> fig, ax = ivr.plot_ar_confidence_set(cs) ivr.savefig(fig, ART / \"ar_confidence_set\", formats=(\"png\", \"pdf\")) In\u00a0[\u00a0]: Copied! <pre>res_grid = ivr.weakiv_inference(\n    data,\n    beta0=beta_true,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n    grid=(beta_true - 2.0, beta_true + 2.0, 301),\n    return_grid=True,\n)\nfig, ax = res_grid.plot()\nivr.savefig(fig, ART / \"pvalue_curve\", formats=(\"png\", \"pdf\"))\n</pre> res_grid = ivr.weakiv_inference(     data,     beta0=beta_true,     alpha=0.05,     methods=(\"AR\", \"LM\", \"CLR\"),     cov_type=\"HC1\",     grid=(beta_true - 2.0, beta_true + 2.0, 301),     return_grid=True, ) fig, ax = res_grid.plot() ivr.savefig(fig, ART / \"pvalue_curve\", formats=(\"png\", \"pdf\"))"},{"location":"notebooks/00_quickstart/#ivrobust-quickstart","title":"ivrobust - Quickstart\u00b6","text":"<p>This notebook runs the smallest end-to-end workflow:</p> <ol> <li>Simulate a weak-IV dataset</li> <li>Run weak-IV robust tests (AR/LM/CLR)</li> <li>Compute confidence sets</li> <li>Save one publication-style figure</li> </ol>"},{"location":"notebooks/00_quickstart/#implementation-context-for-contributors","title":"Implementation context (for contributors)\u00b6","text":"<ul> <li>What to build: a single-call weak-IV inference workflow with AR/LM/CLR tests and set-valued confidence sets.</li> <li>Why it matters: applied users want one entry point that makes weak-IV robust inference explicit and reproducible.</li> <li>Literature/benchmarks: Moreira (2003) CLR; Kleibergen (2002) LM/K; Mikusheva (2010) confidence set shapes; Stata weak-IV reporting for CI behavior.</li> <li>Codex-ready tasks: implement <code>weakiv_inference</code>, add <code>lm_test</code>/<code>clr_test</code>, wire plotting helpers, and expose results in the public API.</li> <li>Tests/docs: unit tests against reference implementations + notebooks showing disjoint/unbounded sets with reproducible seeds.</li> </ul>"},{"location":"notebooks/00_quickstart/#interpretation","title":"Interpretation\u00b6","text":"<ul> <li>At the true beta, the AR test should not reject, so the p-value should be comfortably above common significance levels.</li> <li>The confidence set can be wide or even disjoint under weak instruments; this is expected behavior rather than a numerical bug.</li> </ul>"},{"location":"notebooks/00_quickstart/#p-value-curve","title":"P-value curve\u00b6","text":"<p>Plot p-values across a beta grid to visualize how acceptance changes.</p>"},{"location":"notebooks/01_practitioner_workflow_single_endog/","title":"Practitioner workflow (single endogenous regressor)","text":"In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport ivrobust as ivr\n\nART = Path(\"artifacts\") / \"01_practitioner_workflow_single_endog\"\nART.mkdir(parents=True, exist_ok=True)\n\nivr.set_style()\n</pre> from pathlib import Path  import matplotlib.pyplot as plt import ivrobust as ivr  ART = Path(\"artifacts\") / \"01_practitioner_workflow_single_endog\" ART.mkdir(parents=True, exist_ok=True)  ivr.set_style() In\u00a0[\u00a0]: Copied! <pre>data, beta_true = ivr.weak_iv_dgp(n=400, k=6, strength=0.35, beta=1.0, seed=1)\n</pre> data, beta_true = ivr.weak_iv_dgp(n=400, k=6, strength=0.35, beta=1.0, seed=1) In\u00a0[\u00a0]: Copied! <pre>res = ivr.weakiv_inference(\n    data,\n    beta0=beta_true,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n)\nres.tests[\"AR\"].pvalue, res.tests[\"LM\"].pvalue, res.tests[\"CLR\"].pvalue\n</pre> res = ivr.weakiv_inference(     data,     beta0=beta_true,     alpha=0.05,     methods=(\"AR\", \"LM\", \"CLR\"),     cov_type=\"HC1\", ) res.tests[\"AR\"].pvalue, res.tests[\"LM\"].pvalue, res.tests[\"CLR\"].pvalue In\u00a0[\u00a0]: Copied! <pre>cs_ar = res.confidence_sets[\"AR\"]\ncs_ar.intervals\n</pre> cs_ar = res.confidence_sets[\"AR\"] cs_ar.intervals In\u00a0[\u00a0]: Copied! <pre>fig, ax = ivr.plot_ar_confidence_set(cs_ar)\nivr.savefig(fig, ART / \"ar_confidence_set\", formats=(\"png\", \"pdf\"))\n</pre> fig, ax = ivr.plot_ar_confidence_set(cs_ar) ivr.savefig(fig, ART / \"ar_confidence_set\", formats=(\"png\", \"pdf\")) In\u00a0[\u00a0]: Copied! <pre>grid_res = ivr.weakiv_inference(\n    data,\n    beta0=beta_true,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n    grid=(beta_true - 2.0, beta_true + 2.0, 301),\n    return_grid=True,\n)\nfig, ax = grid_res.plot()\nax.set_title(\"AR/LM/CLR p-value curves\")\nivr.savefig(fig, ART / \"pvalue_curves_ar_lm_clr\", formats=(\"png\", \"pdf\"))\n</pre> grid_res = ivr.weakiv_inference(     data,     beta0=beta_true,     alpha=0.05,     methods=(\"AR\", \"LM\", \"CLR\"),     cov_type=\"HC1\",     grid=(beta_true - 2.0, beta_true + 2.0, 301),     return_grid=True, ) fig, ax = grid_res.plot() ax.set_title(\"AR/LM/CLR p-value curves\") ivr.savefig(fig, ART / \"pvalue_curves_ar_lm_clr\", formats=(\"png\", \"pdf\")) In\u00a0[\u00a0]: Copied! <pre>intervals = cs_ar.intervals\nfig, ax = plt.subplots(figsize=(6.0, 1.6))\nfor lo, hi in intervals:\n    ax.plot([lo, hi], [0.0, 0.0], solid_capstyle=\"butt\")\nax.set_yticks([])\nax.set_xlabel(r\"$\\beta$\")\nax.set_title(\"Union-of-intervals confidence set\")\nivr.savefig(fig, ART / \"ci_interval_diagram\", formats=(\"png\", \"pdf\"))\n</pre> intervals = cs_ar.intervals fig, ax = plt.subplots(figsize=(6.0, 1.6)) for lo, hi in intervals:     ax.plot([lo, hi], [0.0, 0.0], solid_capstyle=\"butt\") ax.set_yticks([]) ax.set_xlabel(r\"$\\beta$\") ax.set_title(\"Union-of-intervals confidence set\") ivr.savefig(fig, ART / \"ci_interval_diagram\", formats=(\"png\", \"pdf\"))"},{"location":"notebooks/01_practitioner_workflow_single_endog/#practitioner-workflow-single-endogenous-regressor","title":"Practitioner workflow (single endogenous regressor)\u00b6","text":""},{"location":"notebooks/01_practitioner_workflow_single_endog/#context","title":"Context\u00b6","text":"<p>This notebook shows an end-to-end weak-IV robust workflow using AR/LM/CLR inference for a single endogenous regressor.</p>"},{"location":"notebooks/01_practitioner_workflow_single_endog/#model-and-estimand","title":"Model and estimand\u00b6","text":"<p>We consider a linear IV model with one endogenous regressor and seek inference on the structural coefficient beta.</p>"},{"location":"notebooks/01_practitioner_workflow_single_endog/#procedure","title":"Procedure\u00b6","text":"<ul> <li>Generate data with <code>weak_iv_dgp</code></li> <li>Run AR/LM/CLR tests at a null beta</li> <li>Invert to confidence sets</li> <li>Visualize p-value curves and confidence sets</li> </ul>"},{"location":"notebooks/01_practitioner_workflow_single_endog/#results","title":"Results\u00b6","text":"<p>We save three figures:</p> <ul> <li>AR confidence set</li> <li>AR/LM/CLR p-value curves</li> <li>Union-of-intervals diagram</li> </ul>"},{"location":"notebooks/01_practitioner_workflow_single_endog/#caveats","title":"Caveats\u00b6","text":"<p>Weak-IV robust confidence sets can be disjoint or unbounded. Report the full set rather than trimming.</p>"},{"location":"notebooks/01_practitioner_workflow_single_endog/#key-takeaways","title":"Key takeaways\u00b6","text":"<ul> <li>AR/LM/CLR remain valid under weak identification.</li> <li>Confidence sets can be nonstandard but still informative.</li> <li>P-value curves help communicate uncertainty.</li> </ul>"},{"location":"notebooks/01_practitioner_workflow_single_endog/#confidence-sets","title":"Confidence sets\u00b6","text":""},{"location":"notebooks/01_practitioner_workflow_single_endog/#p-value-curves","title":"P-value curves\u00b6","text":""},{"location":"notebooks/01_practitioner_workflow_single_endog/#confidence-set-diagram","title":"Confidence set diagram\u00b6","text":""},{"location":"notebooks/02_diagnostics_and_inference/","title":"Diagnostics and inference","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\nimport ivrobust as ivr\n\nART = Path(\"artifacts\") / \"02_diagnostics_and_inference\"\nART.mkdir(parents=True, exist_ok=True)\n\nivr.set_style()\n</pre> from pathlib import Path import ivrobust as ivr  ART = Path(\"artifacts\") / \"02_diagnostics_and_inference\" ART.mkdir(parents=True, exist_ok=True)  ivr.set_style() In\u00a0[2]: Copied! <pre>data, beta_true = ivr.weak_iv_dgp(n=500, k=5, strength=0.2, beta=1.0, seed=2)\ndiag = ivr.first_stage_diagnostics(data)\ndiag\n</pre> data, beta_true = ivr.weak_iv_dgp(n=500, k=5, strength=0.2, beta=1.0, seed=2) diag = ivr.first_stage_diagnostics(data) diag Out[2]: <pre>FirstStageDiagnostics(f_statistic=4.056169152708911, pvalue=0.0012849478284000034, df_num=5, df_denom=494, partial_r2=0.039435351191106305, k_instr=5, nobs=500)</pre> In\u00a0[3]: Copied! <pre>eff = ivr.effective_f(data, cov_type=\"HC1\")\neff\n</pre> eff = ivr.effective_f(data, cov_type=\"HC1\") eff Out[3]: <pre>EffectiveFResult(statistic=4.025602535546341, df_num=5, df_denom=494, cov_type='HC1', nobs=500, k_instr=5, warnings=())</pre> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(1, 2, figsize=(7.2, 3.2))\naxes[0].bar([\"First-stage F\", \"Effective F\"], [diag.f_statistic, eff.statistic])\naxes[0].set_ylabel(\"Statistic\")\naxes[0].set_title(\"Instrument strength diagnostics\")\naxes[1].bar([\"Partial R^2\"], [diag.partial_r2])\naxes[1].set_ylim(0.0, 1.0)\naxes[1].set_title(\"Partial R^2\")\nivr.savefig(fig, ART / \"diagnostics_summary\", formats=(\"png\", \"pdf\"))\n</pre> import matplotlib.pyplot as plt  fig, axes = plt.subplots(1, 2, figsize=(7.2, 3.2)) axes[0].bar([\"First-stage F\", \"Effective F\"], [diag.f_statistic, eff.statistic]) axes[0].set_ylabel(\"Statistic\") axes[0].set_title(\"Instrument strength diagnostics\") axes[1].bar([\"Partial R^2\"], [diag.partial_r2]) axes[1].set_ylim(0.0, 1.0) axes[1].set_title(\"Partial R^2\") ivr.savefig(fig, ART / \"diagnostics_summary\", formats=(\"png\", \"pdf\")) <p>A low first-stage F-statistic and partial R^2 indicate weak instruments. In this regime, conventional standard errors can be misleading, so we rely on AR inference for valid statements about beta.</p> In\u00a0[4]: Copied! <pre>tsls_res = ivr.tsls(data, cov_type=\"HC1\")\ntsls_res.beta, tsls_res.stderr[-1, 0]\n</pre> tsls_res = ivr.tsls(data, cov_type=\"HC1\") tsls_res.beta, tsls_res.stderr[-1, 0] Out[4]: <pre>(1.0900664937349813, np.float64(0.22963407113386372))</pre> <p>This point estimate is useful for reporting, but interpret the standard error with caution when instrument strength is weak.</p> In\u00a0[5]: Copied! <pre>weakiv = ivr.weakiv_inference(\n    data,\n    beta0=beta_true,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n)\nweakiv.confidence_sets[\"AR\"].confidence_set.intervals\n</pre> weakiv = ivr.weakiv_inference(     data,     beta0=beta_true,     alpha=0.05,     methods=(\"AR\", \"LM\", \"CLR\"),     cov_type=\"HC1\", ) weakiv.confidence_sets[\"AR\"].confidence_set.intervals <pre>/Users/gabrielsaco/Documents/GitHub/ivrobust/src/ivrobust/diagnostics/strength.py:209: IVRobustWarning: weak_id: effective F below 10 (F_eff=4.03)\n  warn(\n</pre> Out[5]: <pre>[(-0.25963020093760275, 0.9915771570647243)]</pre> <p>The AR confidence set is robust to weak identification and may be wider than conventional confidence intervals, reflecting true uncertainty.</p> In\u00a0[6]: Copied! <pre>fig, ax = ivr.plot_ar_confidence_set(weakiv.confidence_sets[\"AR\"])\nivr.savefig(fig, ART / \"ar_confidence_set\", formats=(\"png\", \"pdf\"))\n</pre> fig, ax = ivr.plot_ar_confidence_set(weakiv.confidence_sets[\"AR\"]) ivr.savefig(fig, ART / \"ar_confidence_set\", formats=(\"png\", \"pdf\")) Out[6]: <pre>[PosixPath('../artifacts/02_diagnostics_and_inference/ar_confidence_set.png'),\n PosixPath('../artifacts/02_diagnostics_and_inference/ar_confidence_set.pdf')]</pre> <p></p>"},{"location":"notebooks/02_diagnostics_and_inference/#diagnostics-and-inference","title":"Diagnostics and inference\u00b6","text":"<p>This notebook focuses on:</p> <ul> <li>First-stage reporting (F-statistic, partial R^2)</li> <li>Effective F (Montiel Olea\u2013Pflueger)</li> <li>Interpreting weak-IV robust confidence sets</li> <li>Comparing conventional and weak-IV robust outputs</li> </ul>"},{"location":"notebooks/02_diagnostics_and_inference/#implementation-context-for-contributors","title":"Implementation context (for contributors)\u00b6","text":"<ul> <li>What to build: effective F diagnostics and unified inference reporting.</li> <li>Why it matters: classical first-stage F can be misleading under heteroskedasticity or clustering.</li> <li>Literature/benchmarks: Montiel Olea &amp; Pflueger (2013); Andrews\u2013Stock\u2013Sun (2019).</li> <li>Codex-ready tasks: add <code>effective_f</code> and integrate into results summaries.</li> <li>Tests/docs: unit tests comparing effective F to classical F under iid settings.</li> </ul>"},{"location":"notebooks/02_diagnostics_and_inference/#diagnostic-summary-plot","title":"Diagnostic summary plot\u00b6","text":"<p>Compare classical first-stage F and effective F side-by-side.</p>"},{"location":"notebooks/02_diagnostics_and_inference/#conventional-estimator-2sls","title":"Conventional estimator (2SLS)\u00b6","text":""},{"location":"notebooks/02_diagnostics_and_inference/#weak-iv-robust-inference","title":"Weak-IV robust inference\u00b6","text":""},{"location":"notebooks/04_many_instruments_bias_tsls_liml_fuller/","title":"Many instruments: bias in TSLS vs LIML vs Fuller","text":"In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\nimport os\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ivrobust as ivr\n\nART = Path(\"artifacts\") / \"04_many_instruments_bias_tsls_liml_fuller\"\nART.mkdir(parents=True, exist_ok=True)\n\nivr.set_style()\n</pre> from pathlib import Path import os  import numpy as np import matplotlib.pyplot as plt import ivrobust as ivr  ART = Path(\"artifacts\") / \"04_many_instruments_bias_tsls_liml_fuller\" ART.mkdir(parents=True, exist_ok=True)  ivr.set_style() In\u00a0[\u00a0]: Copied! <pre>n = 250\nk_grid = [2, 5, 10, 20]\nstrength = 0.3\nbeta_true = 1.0\nR = int(os.getenv(\"IVROBUST_MC_REPS\", \"40\"))\n\ntsls_bias = []\nliml_bias = []\nfuller_bias = []\ntsls_rmse = []\nliml_rmse = []\nfuller_rmse = []\n\ndist_data = {}\n\nfor k in k_grid:\n    tsls_est = []\n    liml_est = []\n    fuller_est = []\n    for r in range(R):\n        data, _ = ivr.weak_iv_dgp(\n            n=n, k=k, strength=strength, beta=beta_true, seed=r\n        )\n        tsls_est.append(ivr.tsls(data, cov_type=\"HC1\").beta)\n        liml_est.append(ivr.liml(data, cov_type=\"HC1\").beta)\n        fuller_est.append(ivr.fuller(data, alpha=1.0, cov_type=\"HC1\").beta)\n    tsls_est = np.array(tsls_est, dtype=float)\n    liml_est = np.array(liml_est, dtype=float)\n    fuller_est = np.array(fuller_est, dtype=float)\n\n    tsls_bias.append(float(np.mean(tsls_est - beta_true)))\n    liml_bias.append(float(np.mean(liml_est - beta_true)))\n    fuller_bias.append(float(np.mean(fuller_est - beta_true)))\n\n    tsls_rmse.append(float(np.sqrt(np.mean((tsls_est - beta_true) ** 2))))\n    liml_rmse.append(float(np.sqrt(np.mean((liml_est - beta_true) ** 2))))\n    fuller_rmse.append(float(np.sqrt(np.mean((fuller_est - beta_true) ** 2))))\n\n    dist_data[k] = (tsls_est, liml_est, fuller_est)\n\nk_over_n = [k / n for k in k_grid]\n</pre> n = 250 k_grid = [2, 5, 10, 20] strength = 0.3 beta_true = 1.0 R = int(os.getenv(\"IVROBUST_MC_REPS\", \"40\"))  tsls_bias = [] liml_bias = [] fuller_bias = [] tsls_rmse = [] liml_rmse = [] fuller_rmse = []  dist_data = {}  for k in k_grid:     tsls_est = []     liml_est = []     fuller_est = []     for r in range(R):         data, _ = ivr.weak_iv_dgp(             n=n, k=k, strength=strength, beta=beta_true, seed=r         )         tsls_est.append(ivr.tsls(data, cov_type=\"HC1\").beta)         liml_est.append(ivr.liml(data, cov_type=\"HC1\").beta)         fuller_est.append(ivr.fuller(data, alpha=1.0, cov_type=\"HC1\").beta)     tsls_est = np.array(tsls_est, dtype=float)     liml_est = np.array(liml_est, dtype=float)     fuller_est = np.array(fuller_est, dtype=float)      tsls_bias.append(float(np.mean(tsls_est - beta_true)))     liml_bias.append(float(np.mean(liml_est - beta_true)))     fuller_bias.append(float(np.mean(fuller_est - beta_true)))      tsls_rmse.append(float(np.sqrt(np.mean((tsls_est - beta_true) ** 2))))     liml_rmse.append(float(np.sqrt(np.mean((liml_est - beta_true) ** 2))))     fuller_rmse.append(float(np.sqrt(np.mean((fuller_est - beta_true) ** 2))))      dist_data[k] = (tsls_est, liml_est, fuller_est)  k_over_n = [k / n for k in k_grid] In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(6.0, 3.8))\nax.plot(k_over_n, tsls_bias, marker=\"o\", label=\"TSLS\")\nax.plot(k_over_n, liml_bias, marker=\"s\", label=\"LIML\")\nax.plot(k_over_n, fuller_bias, marker=\"^\", label=\"Fuller\")\nax.axhline(0.0, color=\"black\", linestyle=\"--\", linewidth=1.0)\nax.set_xlabel(\"k/n\")\nax.set_ylabel(\"bias\")\nax.set_title(\"Estimator bias vs k/n\")\nax.legend(frameon=False)\nivr.savefig(fig, ART / \"bias_vs_k_over_n\", formats=(\"png\", \"pdf\"))\n</pre> fig, ax = plt.subplots(figsize=(6.0, 3.8)) ax.plot(k_over_n, tsls_bias, marker=\"o\", label=\"TSLS\") ax.plot(k_over_n, liml_bias, marker=\"s\", label=\"LIML\") ax.plot(k_over_n, fuller_bias, marker=\"^\", label=\"Fuller\") ax.axhline(0.0, color=\"black\", linestyle=\"--\", linewidth=1.0) ax.set_xlabel(\"k/n\") ax.set_ylabel(\"bias\") ax.set_title(\"Estimator bias vs k/n\") ax.legend(frameon=False) ivr.savefig(fig, ART / \"bias_vs_k_over_n\", formats=(\"png\", \"pdf\")) In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(6.0, 3.8))\nax.plot(k_over_n, tsls_rmse, marker=\"o\", label=\"TSLS\")\nax.plot(k_over_n, liml_rmse, marker=\"s\", label=\"LIML\")\nax.plot(k_over_n, fuller_rmse, marker=\"^\", label=\"Fuller\")\nax.set_xlabel(\"k/n\")\nax.set_ylabel(\"RMSE\")\nax.set_title(\"Estimator RMSE vs k/n\")\nax.legend(frameon=False)\nivr.savefig(fig, ART / \"rmse_vs_k_over_n\", formats=(\"png\", \"pdf\"))\n</pre> fig, ax = plt.subplots(figsize=(6.0, 3.8)) ax.plot(k_over_n, tsls_rmse, marker=\"o\", label=\"TSLS\") ax.plot(k_over_n, liml_rmse, marker=\"s\", label=\"LIML\") ax.plot(k_over_n, fuller_rmse, marker=\"^\", label=\"Fuller\") ax.set_xlabel(\"k/n\") ax.set_ylabel(\"RMSE\") ax.set_title(\"Estimator RMSE vs k/n\") ax.legend(frameon=False) ivr.savefig(fig, ART / \"rmse_vs_k_over_n\", formats=(\"png\", \"pdf\")) In\u00a0[\u00a0]: Copied! <pre>max_k = max(k_grid)\ntsls_est, liml_est, fuller_est = dist_data[max_k]\n\nfig, ax = plt.subplots(figsize=(6.4, 3.8))\nax.hist(tsls_est, bins=18, alpha=0.6, label=\"TSLS\", density=True)\nax.hist(liml_est, bins=18, alpha=0.6, label=\"LIML\", density=True)\nax.hist(fuller_est, bins=18, alpha=0.6, label=\"Fuller\", density=True)\nax.axvline(beta_true, color=\"black\", linestyle=\"--\", linewidth=1.0)\nax.set_title(f\"Sampling distributions (k={max_k})\")\nax.set_xlabel(\"beta estimate\")\nax.legend(frameon=False)\nivr.savefig(fig, ART / \"sampling_distributions\", formats=(\"png\", \"pdf\"))\n</pre> max_k = max(k_grid) tsls_est, liml_est, fuller_est = dist_data[max_k]  fig, ax = plt.subplots(figsize=(6.4, 3.8)) ax.hist(tsls_est, bins=18, alpha=0.6, label=\"TSLS\", density=True) ax.hist(liml_est, bins=18, alpha=0.6, label=\"LIML\", density=True) ax.hist(fuller_est, bins=18, alpha=0.6, label=\"Fuller\", density=True) ax.axvline(beta_true, color=\"black\", linestyle=\"--\", linewidth=1.0) ax.set_title(f\"Sampling distributions (k={max_k})\") ax.set_xlabel(\"beta estimate\") ax.legend(frameon=False) ivr.savefig(fig, ART / \"sampling_distributions\", formats=(\"png\", \"pdf\"))"},{"location":"notebooks/04_many_instruments_bias_tsls_liml_fuller/#many-instruments-bias-in-tsls-vs-liml-vs-fuller","title":"Many instruments: bias in TSLS vs LIML vs Fuller\u00b6","text":""},{"location":"notebooks/04_many_instruments_bias_tsls_liml_fuller/#context","title":"Context\u00b6","text":"<p>When k grows relative to n, TSLS can exhibit finite-sample bias. LIML and Fuller are often less biased in many-instrument settings.</p>"},{"location":"notebooks/04_many_instruments_bias_tsls_liml_fuller/#model-and-estimand","title":"Model and estimand\u00b6","text":"<p>Scalar endogenous regressor with varying number of instruments.</p>"},{"location":"notebooks/04_many_instruments_bias_tsls_liml_fuller/#procedure","title":"Procedure\u00b6","text":"<ul> <li>Vary k relative to n</li> <li>Compare TSLS, LIML, and Fuller bias and RMSE</li> </ul>"},{"location":"notebooks/04_many_instruments_bias_tsls_liml_fuller/#key-takeaways","title":"Key takeaways\u00b6","text":"<ul> <li>Bias can grow as k/n increases.</li> <li>LIML and Fuller often reduce bias compared to TSLS.</li> </ul>"},{"location":"notebooks/04_many_instruments_bias_tsls_liml_fuller/#bias-vs-kn","title":"Bias vs k/n\u00b6","text":""},{"location":"notebooks/04_many_instruments_bias_tsls_liml_fuller/#rmse-vs-kn","title":"RMSE vs k/n\u00b6","text":""},{"location":"notebooks/04_many_instruments_bias_tsls_liml_fuller/#sampling-distributions-largest-k","title":"Sampling distributions (largest k)\u00b6","text":""},{"location":"notebooks/04_real_data_example/","title":"Real data example (open dataset)","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport ivrobust as ivr\n\nART = Path(\"artifacts\") / \"04_real_data_example\"\nART.mkdir(parents=True, exist_ok=True)\n\nivr.set_style()\n</pre> from pathlib import Path import numpy as np import pandas as pd import ivrobust as ivr  ART = Path(\"artifacts\") / \"04_real_data_example\" ART.mkdir(parents=True, exist_ok=True)  ivr.set_style() In\u00a0[2]: Copied! <pre>url = \"https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/AER/CollegeDistance.csv\"\ndf = pd.read_csv(url)\ndf.head()\n</pre> url = \"https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/AER/CollegeDistance.csv\" df = pd.read_csv(url) df.head() Out[2]: rownames gender ethnicity score fcollege mcollege home urban unemp wage distance tuition education income region 0 1 male other 39.150002 yes no yes yes 6.2 8.09 0.2 0.88915 12 high other 1 2 female other 48.869999 no no yes yes 6.2 8.09 0.2 0.88915 12 low other 2 3 male other 48.740002 no no yes yes 6.2 8.09 0.2 0.88915 12 low other 3 4 male afam 40.400002 no no yes yes 6.2 8.09 0.2 0.88915 12 low other 4 5 female other 40.480000 no no no yes 5.6 8.09 0.4 0.88915 13 low other In\u00a0[3]: Copied! <pre>def pick(colnames):\n    for c in colnames:\n        if c in df.columns:\n            return c\n    raise KeyError(f\"None of {colnames} found\")\n\ny_col = pick([\"wage\"])\nd_col = pick([\"education\"])\nz_col = pick([\"distance\"])\n\ncontrols = [\n    c\n    for c in [\"score\", \"unemp\", \"tuition\"]\n    if c in df.columns\n]\n\nuse = [y_col, d_col, z_col] + controls\ndff = df[use].dropna().copy()\n\ny = dff[y_col].to_numpy(dtype=float).reshape(-1, 1)\nd = dff[d_col].to_numpy(dtype=float).reshape(-1, 1)\nz = dff[z_col].to_numpy(dtype=float).reshape(-1, 1)\n\nx_list = [np.ones((len(dff), 1))]\nfor c in controls:\n    x_list.append(dff[c].to_numpy(dtype=float).reshape(-1, 1))\nx = np.hstack(x_list)\n\ndata = ivr.IVData(y=y, d=d, x=x, z=z)\ndata.nobs\n</pre> def pick(colnames):     for c in colnames:         if c in df.columns:             return c     raise KeyError(f\"None of {colnames} found\")  y_col = pick([\"wage\"]) d_col = pick([\"education\"]) z_col = pick([\"distance\"])  controls = [     c     for c in [\"score\", \"unemp\", \"tuition\"]     if c in df.columns ]  use = [y_col, d_col, z_col] + controls dff = df[use].dropna().copy()  y = dff[y_col].to_numpy(dtype=float).reshape(-1, 1) d = dff[d_col].to_numpy(dtype=float).reshape(-1, 1) z = dff[z_col].to_numpy(dtype=float).reshape(-1, 1)  x_list = [np.ones((len(dff), 1))] for c in controls:     x_list.append(dff[c].to_numpy(dtype=float).reshape(-1, 1)) x = np.hstack(x_list)  data = ivr.IVData(y=y, d=d, x=x, z=z) data.nobs Out[3]: <pre>4739</pre> <p>This specification is intentionally minimal and uses only numeric controls to keep the example transparent and easy to reproduce. In applied work, you would typically add richer controls and consider alternative instruments.</p> In\u00a0[4]: Copied! <pre>tsls_res = ivr.tsls(data, cov_type=\"HC1\")\ntsls_res.beta, tsls_res.stderr[-1, 0]\n</pre> tsls_res = ivr.tsls(data, cov_type=\"HC1\") tsls_res.beta, tsls_res.stderr[-1, 0] Out[4]: <pre>(0.37715367584046605, np.float64(0.16665717334109237))</pre> <p>The 2SLS estimate provides a conventional point estimate. Its standard error is not weak-IV robust, so treat it as descriptive when identification is uncertain.</p> In\u00a0[\u00a0]: Copied! <pre>beta_hat = float(tsls_res.beta)\ncs = ivr.ar_confidence_set(data, alpha=0.05, cov_type=\"HC1\", beta_bounds=(beta_hat - 2.0, beta_hat + 2.0))\ncs.confidence_set.intervals\n</pre> beta_hat = float(tsls_res.beta) cs = ivr.ar_confidence_set(data, alpha=0.05, cov_type=\"HC1\", beta_bounds=(beta_hat - 2.0, beta_hat + 2.0)) cs.confidence_set.intervals <p>The AR confidence set reflects weak-IV uncertainty and can be wider than a conventional interval. If the set is broad, the data provide limited information about the causal effect.</p> In\u00a0[\u00a0]: Copied! <pre>fig, ax = ivr.plot_ar_confidence_set(cs)\nivr.savefig(fig, ART / \"ar_confidence_set\", formats=(\"png\", \"pdf\"))\n</pre> fig, ax = ivr.plot_ar_confidence_set(cs) ivr.savefig(fig, ART / \"ar_confidence_set\", formats=(\"png\", \"pdf\")) <p></p> In\u00a0[\u00a0]: Copied! <pre>weakiv_grid = ivr.weakiv_inference(\n    data,\n    beta0=beta_hat,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n    grid=(beta_hat - 2.0, beta_hat + 2.0, 301),\n    return_grid=True,\n)\nfig, ax = weakiv_grid.plot()\nivr.savefig(fig, ART / \"pvalue_curve\", formats=(\"png\", \"pdf\"))\n</pre> weakiv_grid = ivr.weakiv_inference(     data,     beta0=beta_hat,     alpha=0.05,     methods=(\"AR\", \"LM\", \"CLR\"),     cov_type=\"HC1\",     grid=(beta_hat - 2.0, beta_hat + 2.0, 301),     return_grid=True, ) fig, ax = weakiv_grid.plot() ivr.savefig(fig, ART / \"pvalue_curve\", formats=(\"png\", \"pdf\")) <p></p>"},{"location":"notebooks/04_real_data_example/#real-data-example-open-dataset","title":"Real data example (open dataset)\u00b6","text":"<p>This notebook demonstrates an end-to-end IV workflow on an openly available dataset downloaded in-notebook.</p> <p>We use the <code>AER::CollegeDistance</code> dataset via Rdatasets.</p>"},{"location":"notebooks/04_real_data_example/#implementation-context-for-contributors","title":"Implementation context (for contributors)\u00b6","text":"<ul> <li>What to build: real-data workflow with weak-IV robust inference outputs.</li> <li>Why it matters: applied users want an end-to-end example they can adapt.</li> <li>Literature/benchmarks: Stata weak-IV reporting; estimatr-style regression UX.</li> <li>Codex-ready tasks: add <code>weakiv_inference</code> and diagnostic reporting.</li> <li>Tests/docs: keep runtime short; guard against network failures.</li> </ul>"},{"location":"notebooks/04_real_data_example/#define-a-simple-iv-specification","title":"Define a simple IV specification\u00b6","text":"<p>This example is intentionally minimal: one endogenous regressor and one excluded instrument.</p> <ul> <li>Outcome: wage (hourly wage)</li> <li>Endogenous regressor: education (years of schooling)</li> <li>Instrument: distance to college (distance)</li> <li>Exogenous controls: intercept plus selected numeric controls</li> </ul> <p>Column names vary slightly across distributions; we defensively select available variables.</p>"},{"location":"notebooks/04_real_data_example/#2sls-estimate-workflow","title":"2SLS estimate (workflow)\u00b6","text":""},{"location":"notebooks/04_real_data_example/#weak-iv-robust-ar-confidence-set","title":"Weak-IV robust AR confidence set\u00b6","text":""},{"location":"notebooks/04_real_data_example/#p-value-curve-for-arlmclr","title":"P-value curve for AR/LM/CLR\u00b6","text":"<p>Visualize weak-IV p-values over a beta grid.</p>"},{"location":"notebooks/08_runtime_scaling/","title":"Runtime scaling","text":"In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\nimport time\nimport numpy as np\nimport ivrobust as ivr\n\nART = Path(\"artifacts\") / \"08_runtime_scaling\"\nART.mkdir(parents=True, exist_ok=True)\n\nivr.set_style()\n</pre> from pathlib import Path import time import numpy as np import ivrobust as ivr  ART = Path(\"artifacts\") / \"08_runtime_scaling\" ART.mkdir(parents=True, exist_ok=True)  ivr.set_style() In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\nrng = np.random.default_rng(31)\nconfigs = [\n    (150, 3),\n    (250, 5),\n    (400, 7),\n]\n\ntimings = []\nfor n, k in configs:\n    data, beta_true = ivr.weak_iv_dgp(\n        n=n,\n        k=k,\n        strength=0.4,\n        beta=1.0,\n        seed=int(rng.integers(0, 1_000_000)),\n    )\n    start = time.perf_counter()\n    _ = ivr.weakiv_inference(\n        data,\n        beta0=beta_true,\n        alpha=0.05,\n        methods=(\"AR\", \"LM\", \"CLR\"),\n        cov_type=\"HC1\",\n        grid=(beta_true - 1.5, beta_true + 1.5, 301),\n        return_grid=False,\n    )\n    timings.append(time.perf_counter() - start)\n\ntimings = np.asarray(timings)\n\nfig, ax = plt.subplots(figsize=(6.2, 3.6))\nlabels = [f\"n={n}, k={k}\" for n, k in configs]\nax.plot(range(len(labels)), timings, marker=\"o\")\nax.set_xticks(range(len(labels)), labels)\nax.set_ylabel(\"Runtime (seconds)\")\nax.set_title(\"Runtime vs sample size and instruments\")\nivr.savefig(fig, ART / \"runtime_by_nk\", formats=(\"png\", \"pdf\"))\n</pre> import matplotlib.pyplot as plt  rng = np.random.default_rng(31) configs = [     (150, 3),     (250, 5),     (400, 7), ]  timings = [] for n, k in configs:     data, beta_true = ivr.weak_iv_dgp(         n=n,         k=k,         strength=0.4,         beta=1.0,         seed=int(rng.integers(0, 1_000_000)),     )     start = time.perf_counter()     _ = ivr.weakiv_inference(         data,         beta0=beta_true,         alpha=0.05,         methods=(\"AR\", \"LM\", \"CLR\"),         cov_type=\"HC1\",         grid=(beta_true - 1.5, beta_true + 1.5, 301),         return_grid=False,     )     timings.append(time.perf_counter() - start)  timings = np.asarray(timings)  fig, ax = plt.subplots(figsize=(6.2, 3.6)) labels = [f\"n={n}, k={k}\" for n, k in configs] ax.plot(range(len(labels)), timings, marker=\"o\") ax.set_xticks(range(len(labels)), labels) ax.set_ylabel(\"Runtime (seconds)\") ax.set_title(\"Runtime vs sample size and instruments\") ivr.savefig(fig, ART / \"runtime_by_nk\", formats=(\"png\", \"pdf\")) In\u00a0[\u00a0]: Copied! <pre>base_data, beta_true = ivr.weak_iv_dgp(\n    n=250,\n    k=5,\n    strength=0.4,\n    beta=1.0,\n    seed=123,\n)\n\ngrid_sizes = [301, 401, 501]\nsize_times = []\nfor n_grid in grid_sizes:\n    start = time.perf_counter()\n    _ = ivr.weakiv_inference(\n        base_data,\n        beta0=beta_true,\n        alpha=0.05,\n        methods=(\"AR\", \"LM\", \"CLR\"),\n        cov_type=\"HC1\",\n        grid=(beta_true - 1.5, beta_true + 1.5, n_grid),\n        return_grid=False,\n    )\n    size_times.append(time.perf_counter() - start)\n\nfig, ax = plt.subplots(figsize=(6.0, 3.4))\nax.plot(grid_sizes, size_times, marker=\"o\")\nax.set_xlabel(\"Grid size\")\nax.set_ylabel(\"Runtime (seconds)\")\nax.set_title(\"Runtime vs grid length\")\nivr.savefig(fig, ART / \"runtime_by_grid\", formats=(\"png\", \"pdf\"))\n</pre> base_data, beta_true = ivr.weak_iv_dgp(     n=250,     k=5,     strength=0.4,     beta=1.0,     seed=123, )  grid_sizes = [301, 401, 501] size_times = [] for n_grid in grid_sizes:     start = time.perf_counter()     _ = ivr.weakiv_inference(         base_data,         beta0=beta_true,         alpha=0.05,         methods=(\"AR\", \"LM\", \"CLR\"),         cov_type=\"HC1\",         grid=(beta_true - 1.5, beta_true + 1.5, n_grid),         return_grid=False,     )     size_times.append(time.perf_counter() - start)  fig, ax = plt.subplots(figsize=(6.0, 3.4)) ax.plot(grid_sizes, size_times, marker=\"o\") ax.set_xlabel(\"Grid size\") ax.set_ylabel(\"Runtime (seconds)\") ax.set_title(\"Runtime vs grid length\") ivr.savefig(fig, ART / \"runtime_by_grid\", formats=(\"png\", \"pdf\"))"},{"location":"notebooks/08_runtime_scaling/#runtime-scaling","title":"Runtime scaling\u00b6","text":"<p>This notebook gives a lightweight view of runtime scaling for weak-IV inference grids. It is intentionally small to keep CI runtime manageable.</p>"},{"location":"notebooks/08_runtime_scaling/#runtime-vs-grid-size","title":"Runtime vs grid size\u00b6","text":"<p>Hold n and k fixed, then vary the grid length used for inversion.</p>"},{"location":"reference/api/","title":"API reference","text":"<p>The API is organized around a unified weak-IV workflow, then the individual methods, diagnostics, and data structures that support it.</p>"},{"location":"reference/api/#unified-workflow","title":"Unified workflow","text":""},{"location":"reference/api/#ivrobust.weakiv.ar_confidence_set","title":"<code>ar_confidence_set(data: IVData, *, alpha: float = 0.05, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', grid: FloatArray | None = None, beta_bounds: tuple[float, float] | None = None, n_grid: int = 2001, refine: bool = True, refine_tol: float = 1e-06, max_refine_iter: int = 80) -&gt; ConfidenceSetResult</code>","text":"<p>Invert the AR test to obtain a (possibly disjoint) confidence set for beta.</p> <p>Confidence sets are obtained by evaluating the AR p-value on a grid and inverting p(beta) &gt;= alpha. The result can be empty, unbounded, or a union of disjoint intervals when instruments are weak.</p>"},{"location":"reference/api/#ivrobust.weakiv.ar_test","title":"<code>ar_test(data: IVData, beta0: float | Sequence[float], *, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', alpha: float | None = None) -&gt; ARTestResult</code>","text":"<p>Anderson-Rubin test of H0: beta = beta0 (single endogenous regressor).</p> <p>The AR statistic is the (robust) joint Wald test on instruments in the regression of the null-imposed residual y - beta0 * d on [x, z].</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IVData</code> <p>IVData with y, d, x, z arrays. Requires p_endog=1.</p> required <code>beta0</code> <code>float | Sequence[float]</code> <p>Null value for the endogenous coefficient.</p> required <code>cov</code> <code>CovSpec | str | None</code> <p>Covariance configuration. Use cov_type=\"HAC\" with hac_lags/kernel for Newey-West style covariance.</p> <code>None</code> <code>cov_type</code> <code>CovSpec | str | None</code> <p>Covariance configuration. Use cov_type=\"HAC\" with hac_lags/kernel for Newey-West style covariance.</p> <code>None</code> <code>clusters</code> <code>ndarray | None</code> <p>Optional cluster labels (one-way clustering).</p> <code>None</code> <code>hac_lags</code> <code>int | None</code> <p>Number of HAC lags (Newey-West). If None, a default rule is used.</p> <code>None</code> <code>kernel</code> <code>str</code> <p>HAC kernel name (\"bartlett\" or \"parzen\").</p> <code>'bartlett'</code> <code>alpha</code> <code>float | None</code> <p>Optional significance level stored in the result.</p> <code>None</code> <p>Returns:</p> Type Description <code>ARTestResult</code> <p>Test statistic, p-value, and metadata.</p>"},{"location":"reference/api/#ivrobust.weakiv.clr_confidence_set","title":"<code>clr_confidence_set(data: IVData, *, alpha: float = 0.05, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', method: Literal['CLR', 'CQLR'] = 'CQLR', grid: np.ndarray | None = None, beta_bounds: tuple[float, float] | None = None, n_grid: int = 2001, refine: bool = True, refine_tol: float = 1e-06, max_refine_iter: int = 80, tol: float = 1e-06) -&gt; ConfidenceSetResult</code>","text":"<p>Invert the CLR test to obtain a (possibly disjoint) confidence set for beta.</p>"},{"location":"reference/api/#ivrobust.weakiv.clr_test","title":"<code>clr_test(data: IVData, beta0: float | Sequence[float], *, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', method: Literal['CLR', 'CQLR'] = 'CQLR', tol: float = 1e-06) -&gt; CLRTestResult</code>","text":"<p>Conditional likelihood ratio (CLR/CQLR) test for H0: beta = beta0 (scalar).</p>"},{"location":"reference/api/#ivrobust.weakiv.kp_rank_test","title":"<code>kp_rank_test(data: IVData, *, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett') -&gt; LMTestResult</code>","text":"<p>Kleibergen-Paap rk underidentification test (scalar endogenous regressor).</p>"},{"location":"reference/api/#ivrobust.weakiv.weakiv_inference","title":"<code>weakiv_inference(data: IVData, *, beta0: float | Sequence[float] | None = None, alpha: float = 0.05, methods: Iterable[str] = ('AR', 'LM', 'CLR'), cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', grid: np.ndarray | tuple[float, float, int] | None = None, return_grid: bool = False, recommended: str = 'CLR') -&gt; WeakIVInferenceResult</code>","text":"<p>Unified weak-IV robust inference workflow for AR/LM/CLR.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IVData</code> <p>IVData container. Weak-IV robust routines require p_endog=1.</p> required <code>beta0</code> <code>float | Sequence[float] | None</code> <p>Null value for the endogenous coefficient. If None, defaults to 2SLS.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Significance level for confidence sets.</p> <code>0.05</code> <code>methods</code> <code>Iterable[str]</code> <p>Iterable of method names (\"AR\", \"LM\", \"CLR\").</p> <code>('AR', 'LM', 'CLR')</code> <code>cov</code> <code>CovSpec | str | None</code> <p>Covariance configuration shared across methods.</p> <code>None</code> <code>cov_type</code> <code>CovSpec | str | None</code> <p>Covariance configuration shared across methods.</p> <code>None</code> <code>clusters</code> <code>ndarray | None</code> <p>Optional cluster labels for cluster-robust covariance.</p> <code>None</code> <code>hac_lags</code> <code>int | None</code> <p>HAC lag length when cov_type=\"HAC\".</p> <code>None</code> <code>kernel</code> <code>str</code> <p>HAC kernel name (\"bartlett\" or \"parzen\").</p> <code>'bartlett'</code> <code>grid</code> <code>ndarray | tuple[float, float, int] | None</code> <p>Either an explicit grid array or a (low, high, n_grid) tuple.</p> <code>None</code> <code>return_grid</code> <code>bool</code> <p>If True, include p-value grids in confidence set diagnostics.</p> <code>False</code> <code>recommended</code> <code>str</code> <p>Label of the recommended method (default \"CLR\").</p> <code>'CLR'</code> <p>Returns:</p> Type Description <code>WeakIVInferenceResult</code> <p>Tests, confidence sets, diagnostics, and warnings.</p>"},{"location":"reference/api/#core-tests-and-confidence-sets","title":"Core tests and confidence sets","text":""},{"location":"reference/api/#ivrobust.ar.ar_confidence_set","title":"<code>ar_confidence_set(data: IVData, *, alpha: float = 0.05, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', grid: FloatArray | None = None, beta_bounds: tuple[float, float] | None = None, n_grid: int = 2001, refine: bool = True, refine_tol: float = 1e-06, max_refine_iter: int = 80) -&gt; ConfidenceSetResult</code>","text":"<p>Invert the AR test to obtain a (possibly disjoint) confidence set for beta.</p> <p>Confidence sets are obtained by evaluating the AR p-value on a grid and inverting p(beta) &gt;= alpha. The result can be empty, unbounded, or a union of disjoint intervals when instruments are weak.</p>"},{"location":"reference/api/#ivrobust.ar.ar_test","title":"<code>ar_test(data: IVData, beta0: float | Sequence[float], *, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', alpha: float | None = None) -&gt; ARTestResult</code>","text":"<p>Anderson-Rubin test of H0: beta = beta0 (single endogenous regressor).</p> <p>The AR statistic is the (robust) joint Wald test on instruments in the regression of the null-imposed residual y - beta0 * d on [x, z].</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IVData</code> <p>IVData with y, d, x, z arrays. Requires p_endog=1.</p> required <code>beta0</code> <code>float | Sequence[float]</code> <p>Null value for the endogenous coefficient.</p> required <code>cov</code> <code>CovSpec | str | None</code> <p>Covariance configuration. Use cov_type=\"HAC\" with hac_lags/kernel for Newey-West style covariance.</p> <code>None</code> <code>cov_type</code> <code>CovSpec | str | None</code> <p>Covariance configuration. Use cov_type=\"HAC\" with hac_lags/kernel for Newey-West style covariance.</p> <code>None</code> <code>clusters</code> <code>ndarray | None</code> <p>Optional cluster labels (one-way clustering).</p> <code>None</code> <code>hac_lags</code> <code>int | None</code> <p>Number of HAC lags (Newey-West). If None, a default rule is used.</p> <code>None</code> <code>kernel</code> <code>str</code> <p>HAC kernel name (\"bartlett\" or \"parzen\").</p> <code>'bartlett'</code> <code>alpha</code> <code>float | None</code> <p>Optional significance level stored in the result.</p> <code>None</code> <p>Returns:</p> Type Description <code>ARTestResult</code> <p>Test statistic, p-value, and metadata.</p>"},{"location":"reference/api/#ivrobust.lm.kp_lm_test","title":"<code>kp_lm_test(data: IVData, beta0: float | Sequence[float], *, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', alpha: float | None = None) -&gt; LMTestResult</code>","text":"<p>Kleibergen-Paap LM test for H0: beta = beta0 (scalar).</p>"},{"location":"reference/api/#ivrobust.lm.kp_rank_test","title":"<code>kp_rank_test(data: IVData, *, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett') -&gt; LMTestResult</code>","text":"<p>Kleibergen-Paap rk underidentification test (scalar endogenous regressor).</p>"},{"location":"reference/api/#ivrobust.clr.clr_confidence_set","title":"<code>clr_confidence_set(data: IVData, *, alpha: float = 0.05, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', method: Literal['CLR', 'CQLR'] = 'CQLR', grid: np.ndarray | None = None, beta_bounds: tuple[float, float] | None = None, n_grid: int = 2001, refine: bool = True, refine_tol: float = 1e-06, max_refine_iter: int = 80, tol: float = 1e-06) -&gt; ConfidenceSetResult</code>","text":"<p>Invert the CLR test to obtain a (possibly disjoint) confidence set for beta.</p>"},{"location":"reference/api/#ivrobust.clr.clr_test","title":"<code>clr_test(data: IVData, beta0: float | Sequence[float], *, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', method: Literal['CLR', 'CQLR'] = 'CQLR', tol: float = 1e-06) -&gt; CLRTestResult</code>","text":"<p>Conditional likelihood ratio (CLR/CQLR) test for H0: beta = beta0 (scalar).</p>"},{"location":"reference/api/#diagnostics","title":"Diagnostics","text":""},{"location":"reference/api/#ivrobust.diagnostics.EffectiveFResult","title":"<code>EffectiveFResult</code>  <code>dataclass</code>","text":"<p>Effective F statistic for weak-instrument diagnostics (single endogenous regressor).</p>"},{"location":"reference/api/#ivrobust.diagnostics.FirstStageDiagnostics","title":"<code>FirstStageDiagnostics</code>  <code>dataclass</code>","text":"<p>First-stage diagnostics for a single endogenous regressor.</p>"},{"location":"reference/api/#ivrobust.diagnostics.cragg_donald_f","title":"<code>cragg_donald_f(data: IVData) -&gt; float</code>","text":"<p>Cragg-Donald F statistic (scalar endogenous regressor fallback).</p>"},{"location":"reference/api/#ivrobust.diagnostics.effective_f","title":"<code>effective_f(data: IVData, *, cov: CovSpec | str | None = None, cov_type: CovType = 'HC1', clusters: np.ndarray | None = None, hac_lags: int | None = None, kernel: str = 'bartlett') -&gt; EffectiveFResult</code>","text":"<p>Compute the effective F statistic (Montiel Olea &amp; Pflueger) for p_endog=1.</p>"},{"location":"reference/api/#ivrobust.diagnostics.first_stage_diagnostics","title":"<code>first_stage_diagnostics(data: IVData) -&gt; FirstStageDiagnostics</code>","text":"<p>Compute classical first-stage F-statistic and partial R^2.</p>"},{"location":"reference/api/#ivrobust.diagnostics.stock_yogo_critical_values","title":"<code>stock_yogo_critical_values(k_endog: int, k_instr: int, *, size_distortion: float = 0.1) -&gt; float</code>","text":"<p>Stock-Yogo critical values for maximal size distortion (partial table).</p>"},{"location":"reference/api/#estimators-and-model","title":"Estimators and model","text":""},{"location":"reference/api/#data-containers-and-utilities","title":"Data containers and utilities","text":""},{"location":"reference/api/#ivrobust.data.ClusterSpec","title":"<code>ClusterSpec</code>  <code>dataclass</code>","text":"<p>Normalized cluster labels.</p> <p>codes are integer arrays with contiguous labels starting at 0.</p>"},{"location":"reference/api/#ivrobust.data.IVData","title":"<code>IVData</code>  <code>dataclass</code>","text":"<p>Canonical container for linear IV data with a fixed matrix layout.</p> Array shapes <p>y : (n, 1)     Outcome vector (single column). d : (n, p_endog)     Endogenous regressors. Weak-IV robust tests target p_endog=1. x : (n, p_exog)     Exogenous regressors. Include an intercept column if desired. z : (n, k_instr)     Excluded instruments (not including x). clusters : (n,)     Optional cluster labels for cluster-robust covariance.</p> Validation <ul> <li>Arrays are coerced to float64 (or int64 for clusters).</li> <li>NaN/inf values are rejected.</li> <li>All inputs must have the same number of rows.</li> </ul> Notes <ul> <li>Weak-IV robust inference routines in ivrobust currently assume a single   endogenous regressor (p_endog=1).</li> <li>The intercept is not added implicitly unless you use IVData.from_arrays   with add_const=True; provide x with a constant column if desired.</li> </ul>"},{"location":"reference/api/#ivrobust.data.IVData.from_arrays","title":"<code>from_arrays(*, y: FloatArray, d: FloatArray, z: FloatArray, x: FloatArray | None = None, add_const: bool = True, clusters: IntArray | None = None) -&gt; IVData</code>  <code>classmethod</code>","text":"<p>Construct IVData from raw arrays with explicit keyword-only inputs.</p>"},{"location":"reference/api/#ivrobust.data.normalize_clusters","title":"<code>normalize_clusters(clusters: Sequence[np.ndarray] | np.ndarray, *, nobs: int) -&gt; ClusterSpec</code>","text":"<p>Normalize cluster labels to contiguous integer codes.</p> <p>Accepts a 1D array (one-way clustering) or a sequence of 1D arrays.</p>"},{"location":"reference/api/#ivrobust.data.partial_out","title":"<code>partial_out(x: FloatArray, *args: FloatArray) -&gt; tuple[FloatArray, ...]</code>","text":"<p>Residualize each array in args on x using QR-based projections.</p>"},{"location":"reference/api/#ivrobust.data.weak_iv_dgp","title":"<code>weak_iv_dgp(*, n: int, k: int, strength: float, beta: float, seed: int | None = None, rho: float = 0.5) -&gt; tuple[IVData, float]</code>","text":"<p>Generate a synthetic linear IV dataset with one endogenous regressor.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Sample size.</p> required <code>k</code> <code>int</code> <p>Number of excluded instruments.</p> required <code>strength</code> <code>float</code> <p>First-stage strength parameter. Larger values imply stronger relevance.</p> required <code>beta</code> <code>float</code> <p>Structural coefficient on the endogenous regressor.</p> required <code>seed</code> <code>int | None</code> <p>Random seed for reproducibility.</p> <code>None</code> <code>rho</code> <code>float</code> <p>Correlation between structural and first-stage errors (endogeneity).</p> <code>0.5</code> <p>Returns:</p> Type Description <code>(IVData, float)</code> <p>The generated dataset and the true beta used in the DGP.</p>"},{"location":"reference/api/#ivrobust.covariance.compute_moment_cov","title":"<code>compute_moment_cov(*, X: FloatArray, resid: FloatArray, cov_type: CovType | None = 'HC1', clusters: IntArray | ClusterSpec | None = None, cov: CovSpec | str | Mapping[str, object] | None = None, hac_lags: int | None = None, kernel: str = 'bartlett', small_sample_adj: bool = True) -&gt; MomentCovarianceResult</code>","text":"<p>Compute sandwich covariance for moments based on regressors X and residuals.</p>"},{"location":"reference/api/#ivrobust.covariance.cov_ols","title":"<code>cov_ols(*, X: FloatArray, resid: FloatArray, cov_type: CovType | None = 'HC1', clusters: IntArray | ClusterSpec | None = None, cov: CovSpec | str | Mapping[str, object] | None = None, hac_lags: int | None = None, kernel: str = 'bartlett') -&gt; CovarianceResult</code>","text":"<p>Sandwich covariance for OLS coefficients.</p>"},{"location":"reference/api/#ivrobust.covariance.cov_reduced_form","title":"<code>cov_reduced_form(*, X: FloatArray, resid_y: FloatArray, resid_d: FloatArray, cov_type: CovType | None = 'HC1', clusters: IntArray | ClusterSpec | None = None, cov: CovSpec | str | Mapping[str, object] | None = None, small_sample_adj: bool = True, df_resid_adj: int | None = None, hac_lags: int | None = None, kernel: str = 'bartlett') -&gt; ReducedFormCovarianceResult</code>","text":"<p>Sandwich covariance for reduced-form coefficients of (y, d) on X.</p>"},{"location":"reference/api/#ivrobust.intervals.IntervalSet","title":"<code>IntervalSet</code>  <code>dataclass</code>","text":"<p>A (possibly disjoint) set of intervals on the real line.</p> <p>Intervals are represented as (lower, upper), where bounds may be -inf/inf.</p>"},{"location":"reference/api/#ivrobust.intervals.invert_pvalue_grid","title":"<code>invert_pvalue_grid(*, grid: FloatArray, pvalues: FloatArray, alpha: float, refine: bool, refine_tol: float, max_refine_iter: int, pvalue_func: Callable[[float], float] | None) -&gt; IntervalSet</code>","text":"<p>Invert a p-value curve on a grid into a union of intervals.</p>"},{"location":"reference/api/#plotting","title":"Plotting","text":""},{"location":"reference/api/#ivrobust.plots.plot_ar_confidence_set","title":"<code>plot_ar_confidence_set(cs: ConfidenceSetResult, *, ax: Any | None = None) -&gt; tuple[Any, Any]</code>","text":"<p>Plot an AR confidence set as horizontal intervals.</p> <p>Parameters:</p> Name Type Description Default <code>cs</code> <code>ConfidenceSetResult</code> <p>Output from <code>ar_confidence_set</code>.</p> required <code>ax</code> <code>Any | None</code> <p>Optional matplotlib Axes.</p> <code>None</code> <p>Returns:</p> Type Description <code>(fig, ax)</code>"},{"location":"reference/api/#ivrobust.plot_style.savefig","title":"<code>savefig(fig: Any, path: str | Path, *, formats: Iterable[str] = ('png', 'pdf'), dpi: int | None = None) -&gt; list[Path]</code>","text":"<p>Save a figure with ivrobust conventions.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Any</code> <p>Matplotlib Figure.</p> required <code>path</code> <code>str | Path</code> <p>Output path without suffix (recommended) or with suffix.</p> required <code>formats</code> <code>Iterable[str]</code> <p>Iterable of formats, e.g. (\"png\", \"pdf\").</p> <code>('png', 'pdf')</code> <code>dpi</code> <code>int | None</code> <p>Override DPI for raster formats. Default uses rcParams (300).</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>Paths written.</p>"},{"location":"reference/api/#ivrobust.plot_style.set_style","title":"<code>set_style() -&gt; None</code>","text":"<p>Apply the ivrobust plotting style globally (matplotlib rcParams).</p> <p>This is the single style entrypoint. All plotting functions in ivrobust call <code>set_style()</code> internally to prevent drift across the package.</p>"},{"location":"reference/api/#ivrobust.plot_style.style_context","title":"<code>style_context() -&gt; Iterator[None]</code>","text":"<p>Context manager that applies ivrobust style and restores previous rcParams.</p>"},{"location":"reference/results_objects/","title":"Result objects and confidence sets","text":"<p>ivrobust returns structured results to make reporting explicit and reproducible.</p>"},{"location":"reference/results_objects/#testresult","title":"TestResult","text":"<p>Fields:</p> <ul> <li><code>statistic</code>, <code>pvalue</code>, <code>df</code></li> <li><code>method</code>, <code>cov_type</code></li> <li><code>cov_config</code> (e.g., HAC lags, kernel)</li> <li><code>warnings</code>, <code>details</code></li> </ul> <p>Use <code>.summary()</code> for a printable block or <code>.as_dict()</code> for serialization.</p>"},{"location":"reference/results_objects/#confidencesetresult","title":"ConfidenceSetResult","text":"<p>Fields:</p> <ul> <li><code>confidence_set</code> (an <code>IntervalSet</code>)</li> <li><code>alpha</code>, <code>method</code></li> <li><code>grid_info</code> (grid, p-values if requested, runtime, bounds)</li> <li><code>warnings</code></li> </ul> <p>Convenience properties:</p> <ul> <li><code>intervals</code></li> <li><code>is_empty</code>, <code>is_unbounded</code>, <code>is_disjoint</code></li> </ul>"},{"location":"reference/results_objects/#intervalset","title":"IntervalSet","text":"<p><code>IntervalSet</code> represents a union of real-line intervals:</p> <pre><code>IntervalSet(intervals=[(-1.0, 0.0), (2.0, 3.5)])\n</code></pre> <p>Intervals may be unbounded (use <code>-inf</code> or <code>inf</code>). The set can be empty when no values pass the inverted test.</p>"},{"location":"reference/results_objects/#weakivinferenceresult","title":"WeakIVInferenceResult","text":"<p><code>weakiv_inference</code> returns:</p> <ul> <li><code>tests</code>: dict of <code>TestResult</code> objects</li> <li><code>confidence_sets</code>: dict of <code>ConfidenceSetResult</code> objects</li> <li><code>diagnostics</code>: dictionary of strength diagnostics</li> </ul> <p>When <code>return_grid=True</code>, confidence sets include p-value grids for plotting.</p>"},{"location":"reference/stable_api/","title":"Stable public API (0.x contract)","text":"<p>The following names are treated as stable in the 0.x series. Backwards incompatible changes require deprecation warnings before removal.</p>"},{"location":"reference/stable_api/#core-data-dgp","title":"Core data + DGP","text":"<ul> <li><code>IVData</code></li> <li><code>IVData.from_arrays</code></li> <li><code>weak_iv_dgp</code></li> </ul>"},{"location":"reference/stable_api/#weak-iv-robust-inference","title":"Weak-IV robust inference","text":"<ul> <li><code>weakiv_inference</code></li> <li><code>ar_test</code></li> <li><code>ar_confidence_set</code></li> <li><code>lm_test</code></li> <li><code>lm_confidence_set</code></li> <li><code>clr_test</code></li> <li><code>clr_confidence_set</code></li> </ul>"},{"location":"reference/stable_api/#diagnostics","title":"Diagnostics","text":"<ul> <li><code>first_stage_diagnostics</code></li> <li><code>effective_f</code></li> <li><code>weak_id_diagnostics</code></li> <li><code>kp_rank_test</code></li> </ul>"},{"location":"reference/stable_api/#estimators-workflow-support","title":"Estimators (workflow support)","text":"<ul> <li><code>tsls</code></li> <li><code>liml</code></li> <li><code>fuller</code></li> <li><code>fit</code></li> </ul>"},{"location":"reference/stable_api/#plotting","title":"Plotting","text":"<ul> <li><code>set_style</code></li> <li><code>plot_ar_confidence_set</code></li> <li><code>savefig</code></li> </ul> <p>Notes</p> <ul> <li>Weak-IV robust procedures currently target a single endogenous regressor   (<code>p_endog=1</code>).</li> <li>Confidence sets can be empty, unbounded, or disjoint; this is expected under   weak identification.</li> </ul>"},{"location":"user-guide/","title":"User guide","text":"<p>The user guide focuses on weak-IV robust inference workflows, from data setup to publication-ready plots.</p>"},{"location":"user-guide/#what-you-will-learn","title":"What you will learn","text":"<ul> <li>How <code>IVData</code> structures the model and assumptions.</li> <li>When to prefer AR, LM/K, or CLR inference.</li> <li>How to interpret diagnostics and effective F statistics.</li> <li>How to interpret diagnostics and safe defaults for reporting.</li> <li>How to report set-valued confidence sets and p-value curves.</li> </ul>"},{"location":"user-guide/#guide-map","title":"Guide map","text":"<ul> <li> <p> Anderson-Rubin inference</p> <p>Robust inference under weak identification.</p> <p>Read more</p> </li> <li> <p> LM/K test</p> <p>Kleibergen-Paap LM statistics and confidence sets.</p> <p>Read more</p> </li> <li> <p> CLR test</p> <p>Conditional likelihood ratio inference and grids.</p> <p>Read more</p> </li> <li> <p> Estimators</p> <p>2SLS, LIML, Fuller, and k-class estimators.</p> <p>Read more</p> </li> <li> <p> Diagnostics</p> <p>Effective F, weak-ID diagnostics, and rank tests.</p> <p>Read more</p> </li> <li> <p> Diagnostics &amp; interpretation</p> <p>Practical guidance on reading outputs and avoiding pitfalls.</p> <p>Read more</p> </li> <li> <p> Many instruments</p> <p>Guidance when k is large relative to n.</p> <p>Read more</p> </li> <li> <p> Plotting</p> <p>Style conventions and figure output for papers.</p> <p>Read more</p> </li> <li> <p> Choosing a method</p> <p>Decision table for AR/LM/CLR selection and covariance regimes.</p> <p>Read more</p> </li> <li> <p>:material-route: Workflow</p> <p>Estimate -&gt; diagnose -&gt; test -&gt; confidence set workflow.</p> <p>Read more</p> </li> <li> <p> Covariance choices</p> <p>HC, cluster, and HAC options and what they change.</p> <p>Read more</p> </li> <li> <p> Numerics</p> <p>Grid inversion, edge cases, and stability considerations.</p> <p>Read more</p> </li> </ul>"},{"location":"user-guide/ar/","title":"Anderson-Rubin inference","text":"<p>The Anderson-Rubin (AR) approach performs inference on a structural parameter by testing whether excluded instruments predict the null-implied residual. This yields tests that remain valid under weak instruments.</p>"},{"location":"user-guide/ar/#purpose","title":"Purpose","text":"<p>AR provides weak-IV robust inference on a scalar structural parameter. It remains correctly sized even when instruments are weak.</p>"},{"location":"user-guide/ar/#model-and-null","title":"Model and null","text":"<p>Consider a linear IV model with one endogenous regressor \\(d\\):</p> \\[ y = \\beta d + x'\\gamma + u \\] <p>Given a null \\(H_0: \\beta = \\beta_0\\), define the null-implied outcome:</p> \\[ \\tilde y(\\beta_0) = y - \\beta_0 d \\] <p>The AR regression is:</p> \\[ \\tilde y(\\beta_0) \\sim x + z \\] <p>and the AR test is a joint test that coefficients on \\(z\\) are zero.</p>"},{"location":"user-guide/ar/#test-statistic","title":"Test statistic","text":"<p>Let \\(r(\\beta_0) = y - \\beta_0 d\\). The AR statistic is the (robust) Wald test of the coefficients on \\(z\\) in the regression of \\(r(\\beta_0)\\) on \\([x, z]\\).</p>"},{"location":"user-guide/ar/#algorithm","title":"Algorithm","text":"<ol> <li>Residualize \\(y\\), \\(d\\), and \\(z\\) with respect to \\(x\\).</li> <li>Form \\(r(\\beta_0) = y - \\beta_0 d\\).</li> <li>Compute the robust covariance for moments \\(z r(\\beta_0)\\).</li> <li>Form the Wald statistic and p-value under \\(\\chi^2_k\\).</li> </ol>"},{"location":"user-guide/ar/#confidence-set-by-inversion","title":"Confidence set by inversion","text":"<p>The \\((1-\\alpha)\\) confidence set is:</p> \\[ CS_{1-\\alpha} = \\{\\beta : p_{AR}(\\beta) \\ge \\alpha\\}. \\] <p>Intervals may be empty, unbounded, or disjoint.</p>"},{"location":"user-guide/ar/#interpretation","title":"Interpretation","text":"<p>Wide or unbounded sets indicate weak identification: the data contain limited information about \\(\\beta\\).</p>"},{"location":"user-guide/ar/#pitfalls-numerics","title":"Pitfalls / numerics","text":"<ul> <li>Grid bounds can affect numerical inversion; use wide bounds in weak-ID cases.</li> <li>Discontinuities in p-values can create union intervals; report them directly.</li> </ul>"},{"location":"user-guide/ar/#in-ivrobust","title":"In ivrobust","text":"<pre><code>import ivrobust as ivr\ndata, beta_true = ivr.weak_iv_dgp(n=300, k=5, strength=0.4, beta=1.0, seed=0)\n\nres = ivr.ar_test(data, beta0=beta_true, cov_type=\"HC1\")\nres.statistic, res.pvalue\n</code></pre> <p>Covariance options: <code>\"unadjusted\"</code>, <code>\"HC0\"</code>, <code>\"HC1\"</code>, <code>\"HC2\"</code>, <code>\"HC3\"</code>, <code>\"cluster\"</code> (one-way clustering with <code>data.clusters</code>), and <code>\"HAC\"</code> (Newey-West with <code>hac_lags</code> and <code>kernel</code>).</p> <p>Confidence sets return a <code>ConfidenceSetResult</code> with a union-of-intervals object:</p> <p>The AR confidence set is obtained by inverting the AR test across values of \\(\\beta\\).</p> <pre><code>cs = ivr.ar_confidence_set(data, alpha=0.05, cov_type=\"HC1\")\ncs.confidence_set.intervals\n</code></pre> <p>Intervals may be disjoint or unbounded; this is not a bug. It is a feature of weak-identification robust inference.</p> <p>References:</p> <ul> <li>Anderson, T. W., and Rubin, H. (1949). Estimation of the Parameters of a   Single Equation in a Complete System of Stochastic Equations. Annals of   Mathematical Statistics. DOI: 10.1214/aoms/1177730090.</li> <li>Andrews, I., Stock, J. H., and Sun, L. (2019). Weak Instruments in   Instrumental Variables Regression: Theory and Practice. Annual Review of   Economics. DOI: 10.1146/annurev-economics-080218-025643.</li> <li>Mikusheva, A. (2010). Robust confidence sets in the presence of weak   instruments. Journal of Econometrics. DOI: 10.1016/j.jeconom.2009.12.003.</li> </ul> <p>See the References page for formatted citations.</p>"},{"location":"user-guide/choosing/","title":"Choosing a weak-IV robust method","text":"<p>This guide helps you pick an inference method based on your identification concerns, covariance regime, and reporting needs.</p>"},{"location":"user-guide/choosing/#inputs-to-the-decision","title":"Inputs to the decision","text":"<ul> <li>Suspected instrument strength (weak vs strong).</li> <li>Covariance regime (heteroskedastic, cluster, HAC/serial correlation).</li> <li>Whether you need a test, a confidence set, or both.</li> <li>Willingness to report nonstandard confidence sets (disjoint or unbounded).</li> </ul>"},{"location":"user-guide/choosing/#decision-table","title":"Decision table","text":"Scenario Recommended method(s) Notes Instruments likely weak, scalar endogenous regressor AR or CLR AR is simple and robust; CLR often has higher power. You need a single test with good power CLR (CQLR) Use CQLR under heteroskedasticity or clustering. You need a quick robustness check AR + LM LM can complement AR when power differs. Robust covariance required (cluster/HAC) AR/LM/CLR with cov_type set Ensure the method supports the desired covariance regime. Many instruments (k/n not negligible) Report diagnostics + LIML/Fuller Weak-IV tests are still valid for fixed k; warn when k/n is large."},{"location":"user-guide/choosing/#nonstandard-confidence-sets","title":"Nonstandard confidence sets","text":"<p>Weak-IV robust confidence sets are obtained by inversion and can be:</p> <ul> <li>Empty (no values pass the test at alpha).</li> <li>Unbounded (the full real line).</li> <li>A union of disjoint intervals.</li> </ul> <p>These shapes are expected under weak identification and should be reported as they are.</p>"},{"location":"user-guide/choosing/#stata-parity-expectations","title":"Stata parity expectations","text":"<p>Stata's weak-IV postestimation advertises AR/CLR inference, robust covariance options, and nonstandard confidence sets. ivrobust mirrors this workflow and exposes the same objects in Python.</p>"},{"location":"user-guide/clr/","title":"CLR test","text":"<p>The Conditional Likelihood Ratio (CLR) test (Moreira, 2003) is a canonical weak-IV robust test with strong finite-sample properties. Its p-values are computed from a nonstandard distribution that depends on a concentration statistic.</p>"},{"location":"user-guide/clr/#purpose","title":"Purpose","text":"<p>CLR is a weak-IV robust test with strong power properties among invariant tests, especially in overidentified models.</p>"},{"location":"user-guide/clr/#statistic-and-conditioning","title":"Statistic and conditioning","text":"<p>CLR compares the likelihood under the null to the best-fitting reduced-form model and uses a conditional critical value that depends on a concentration statistic.</p>"},{"location":"user-guide/clr/#algorithm","title":"Algorithm","text":"<ol> <li>Compute reduced-form coefficients and covariance.</li> <li>Form CLR quadratic forms and the concentration statistic.</li> <li>Evaluate the conditional p-value and invert over beta for confidence sets.</li> </ol>"},{"location":"user-guide/clr/#confidence-set-behavior","title":"Confidence set behavior","text":"<p>CLR confidence sets are obtained by inversion and can be disjoint or unbounded.</p>"},{"location":"user-guide/clr/#in-ivrobust","title":"In ivrobust","text":"<pre><code>import ivrobust as ivr\ndata, beta_true = ivr.weak_iv_dgp(n=300, k=5, strength=0.4, beta=1.0, seed=0)\n\nres = ivr.clr_test(data, beta0=beta_true, cov_type=\"HC1\", method=\"CQLR\")\nres.statistic, res.pvalue\n\ncs = ivr.clr_confidence_set(data, alpha=0.05, cov_type=\"HC1\")\ncs.confidence_set.intervals\n</code></pre> <p>Notes:</p> <ul> <li>CLR confidence sets can be disjoint or unbounded under weak instruments.</li> <li>Set <code>method=\"CLR\"</code> for homoskedastic CLR; <code>method=\"CQLR\"</code> is the robust default.</li> <li>Use <code>weakiv_inference</code> to compute AR/LM/CLR tests and sets together.</li> <li>Available covariance types: <code>\"unadjusted\"</code>, <code>\"HC0\"</code>, <code>\"HC1\"</code>, <code>\"HC2\"</code>, <code>\"HC3\"</code>, <code>\"cluster\"</code>, <code>\"HAC\"</code>.</li> </ul> <p>References:</p> <ul> <li>Moreira, M. J. (2003). A Conditional Likelihood Ratio Test for Structural   Models. Econometrica.</li> <li>Mikusheva, A. (2010). Robust confidence sets in the presence of weak   instruments. Journal of Econometrics.</li> <li>Finlay, K., and Magnusson, L. M. (2009). Implementing weak-instrument robust   tests for a general class of instrumental-variables models. The Stata Journal.</li> </ul>"},{"location":"user-guide/covariance/","title":"Robust covariance options and what they change","text":"<p>Weak-IV robust tests depend on the covariance of reduced-form moments. This page summarizes the supported covariance types and how they affect inference.</p>"},{"location":"user-guide/covariance/#covariance-options","title":"Covariance options","text":"cov_type Use case Notes <code>unadjusted</code> Homoskedastic iid Classic formulas; used for exact CLR. <code>HC0</code>-<code>HC3</code> Heteroskedasticity Robust sandwich estimators. <code>cluster</code> Grouped data One-way clustered covariance; supply <code>clusters</code>. <code>HAC</code> Serial correlation Newey-West style HAC with <code>hac_lags</code> and <code>kernel</code>."},{"location":"user-guide/covariance/#example","title":"Example","text":"<pre><code>res = ivr.weakiv_inference(\n    data,\n    beta0=0.0,\n    cov_type=\"HAC\",\n    hac_lags=4,\n    kernel=\"bartlett\",\n)\n</code></pre>"},{"location":"user-guide/covariance/#practical-guidance","title":"Practical guidance","text":"<ul> <li>Use <code>HC1</code> as a default in cross-sectional settings.</li> <li>Use <code>cluster</code> when observations are grouped (firms, regions, cohorts).</li> <li>Use <code>HAC</code> in time-series or panel settings with serial correlation.</li> </ul>"},{"location":"user-guide/covariance/#diagnostics-interaction","title":"Diagnostics interaction","text":"<p>Effective F and KP-rk diagnostics are computed using the same covariance specification, so change <code>cov_type</code> consistently across your workflow.</p>"},{"location":"user-guide/diagnostics/","title":"Diagnostics","text":"<p>First-stage strength reporting is standard practice.</p> <p>ivrobust provides:</p> <ul> <li>Classical first-stage F-statistic</li> <li>Partial \\(R^2\\)</li> <li>Effective F (heteroskedasticity/cluster-robust)</li> <li>Kleibergen\u2013Paap rk statistic (underidentification)</li> <li>Cragg\u2013Donald F (scalar endogenous regressor)</li> <li>Stock\u2013Yogo critical values (partial table)</li> </ul> <pre><code>import ivrobust as ivr\ndata, _ = ivr.weak_iv_dgp(n=300, k=5, strength=0.4, beta=1.0, seed=0)\n\ndiag = ivr.first_stage_diagnostics(data)\ndiag.f_statistic, diag.partial_r2\n</code></pre>"},{"location":"user-guide/diagnostics/#effective-f-montiel-olea-pflueger","title":"Effective F (Montiel Olea-Pflueger)","text":"<p>The effective F statistic is designed to remain informative under heteroskedasticity, clustering, or serial correlation. It is based on the robust covariance of the reduced-form coefficients in the first stage.</p> <pre><code>eff = ivr.effective_f(data, cov_type=\"HC1\")\neff.statistic\n</code></pre> <p>Reference: Montiel Olea and Pflueger (2013), DOI: 10.1080/00401706.2013.806694. See the References page for formatted citations.</p>"},{"location":"user-guide/diagnostics/#weak-id-summary","title":"Weak-ID summary","text":"<pre><code>diag = ivr.weak_id_diagnostics(data)\ndiag.kp_rk_stat, diag.kp_rk_pvalue\n</code></pre> <p>The <code>weak_id_diagnostics</code> helper bundles effective F, first-stage F, Kleibergen\u2013Paap rk, and Cragg\u2013Donald statistics for quick reporting.</p> <pre><code>ivr.stock_yogo_critical_values(k_endog=1, k_instr=3, size_distortion=0.10)\n</code></pre>"},{"location":"user-guide/diagnostics/#numerical-stability","title":"Numerical stability","text":"<p>ivrobust uses QR/SVD-based projections in its core linear algebra routines to avoid explicit matrix inversion. Rank-deficient designs trigger warnings and are handled with pseudo-inverse fallbacks where possible.</p>"},{"location":"user-guide/estimators/","title":"Estimators","text":"<p>ivrobust provides 2SLS/LIML/Fuller estimators primarily for workflow support (point estimates, conventional robust standard errors).</p> <p>Important: 2SLS standard errors are not weak-instrument robust. For weak-IV robust inference on the structural coefficient, use AR-based routines.</p> <pre><code>import ivrobust as ivr\ndata, _ = ivr.weak_iv_dgp(n=1000, k=3, strength=0.8, beta=2.0, seed=1)\n\nres = ivr.tsls(data, cov_type=\"HC1\")\nres.beta\n\nliml = ivr.liml(data, cov_type=\"HC1\")\nfuller = ivr.fuller(data, alpha=1.0, cov_type=\"HC1\")\n\nfit = ivr.fit(data, estimator=\"liml\", cov_type=\"HC1\")\nfit.params\n</code></pre> <p>Covariance options</p> <ul> <li><code>cov_type=\"HC0\"|\"HC1\"|\"HC2\"|\"HC3\"</code> for heteroskedasticity-robust SEs</li> <li><code>cov_type=\"cluster\"</code> for one-way cluster robust SEs</li> <li><code>cov_type=\"HAC\"</code> for Newey\u2013West-type SEs (set <code>hac_lags</code> and <code>kernel</code>)</li> </ul>"},{"location":"user-guide/estimators/#model-wrapper","title":"Model wrapper","text":"<p>If you prefer a model-style interface:</p> <pre><code>model = ivr.IVModel.from_arrays(\n    y=data.y,\n    x_endog=data.d,\n    z=data.z,\n    x_exog=None,\n    add_const=True,\n)\nresults = model.fit(estimator=\"liml\", cov_type=\"HC1\")\nresults.params\n</code></pre> <p>You can also call weak-IV robust inference from results:</p> <pre><code>weakiv = results.weakiv(methods=(\"AR\", \"LM\", \"CLR\"), alpha=0.05)\nweakiv.summary()\n</code></pre>"},{"location":"user-guide/lm/","title":"LM/K test","text":"<p>The Lagrange Multiplier (LM) or Kleibergen\u2013Paap K test is a weak-IV robust score test for a scalar structural parameter. It has a chi-square(1) asymptotic distribution under weak instruments.</p>"},{"location":"user-guide/lm/#purpose","title":"Purpose","text":"<p>LM/K provides a score-based alternative to AR. It can have higher power in some settings while retaining weak-ID robustness.</p>"},{"location":"user-guide/lm/#statistic","title":"Statistic","text":"<p>The LM statistic uses the score of the reduced-form likelihood (or its minimum-distance analog) evaluated at the null. In ivrobust it is implemented as the Kleibergen\u2013Paap LM statistic for a scalar endogenous regressor.</p>"},{"location":"user-guide/lm/#algorithm","title":"Algorithm","text":"<ol> <li>Residualize \\(y\\), \\(d\\), and \\(z\\) with respect to \\(x\\).</li> <li>Form the score and information terms under \\(H_0\\).</li> <li>Compute the LM statistic and p-value under \\(\\chi^2_1\\).</li> </ol>"},{"location":"user-guide/lm/#interpretation","title":"Interpretation","text":"<p>LM can be more powerful than AR under some designs but can behave similarly in very weak-ID settings.</p>"},{"location":"user-guide/lm/#in-ivrobust","title":"In ivrobust","text":"<pre><code>import ivrobust as ivr\ndata, beta_true = ivr.weak_iv_dgp(n=300, k=4, strength=0.5, beta=1.0, seed=0)\n\nres = ivr.lm_test(data, beta0=beta_true, cov_type=\"HC1\")\nres.statistic, res.pvalue\n\nrk = ivr.kp_rank_test(data, cov_type=\"HC1\")\nrk.statistic, rk.pvalue\n\ncs = ivr.lm_confidence_set(data, alpha=0.05, cov_type=\"HC1\")\ncs.confidence_set.intervals\n</code></pre> <p>Notes:</p> <ul> <li>LM confidence sets can be disjoint or unbounded under weak instruments.</li> <li>Use <code>cov_type=\"cluster\"</code> for one-way clustering (requires <code>data.clusters</code>).</li> <li>Available covariance types: <code>\"unadjusted\"</code>, <code>\"HC0\"</code>, <code>\"HC1\"</code>, <code>\"HC2\"</code>, <code>\"HC3\"</code>, <code>\"cluster\"</code>.</li> <li>Use <code>cov_type=\"HAC\"</code> with <code>hac_lags</code> and <code>kernel</code> for serial correlation.</li> </ul> <p>References:</p> <ul> <li>Kleibergen, F. (2002). Pivotal statistics for testing structural parameters in   instrumental variables regression. Econometrica.</li> <li>Mikusheva, A. (2010). Robust confidence sets in the presence of weak   instruments. Journal of Econometrics.</li> <li>Finlay, K., and Magnusson, L. M. (2009). Implementing weak-instrument robust   tests for a general class of instrumental-variables models. The Stata Journal.</li> </ul>"},{"location":"user-guide/many_instruments/","title":"Many Instruments","text":"<p>When the number of instruments grows relative to sample size, conventional first-stage F statistics can overstate strength. ivrobust exposes diagnostics that remain meaningful under many-instrument asymptotics.</p> <p>Key diagnostics</p> <ul> <li>Effective F (Montiel Olea\u2013Pflueger): heteroskedastic/cluster-robust strength.</li> <li>Kleibergen\u2013Paap rk statistic: underidentification test.</li> <li>Cragg\u2013Donald F (scalar endog): classical counterpart for comparison.</li> <li>Stock\u2013Yogo critical values: rule-of-thumb thresholds (partial table). <sup>1</sup></li> </ul> <p>Example</p> <pre><code>import ivrobust as ivr\n\ndata, _ = ivr.weak_iv_dgp(n=300, k=10, strength=0.3, beta=1.0, seed=0)\n\ndiag = ivr.weak_id_diagnostics(data)\ndiag.effective_f, diag.kp_rk_stat\n</code></pre> <p>Interpretation</p> <ul> <li>Effective F below ~10 signals weak identification in many settings.</li> <li>The rk test p-value near 0 indicates underidentification.</li> <li>Stock\u2013Yogo critical values provide reference cutoffs for size distortions.</li> </ul> <ol> <li> <p>James H. Stock and Motohiro Yogo. Testing for weak instruments in linear iv regression. Identification and Inference for Econometric Models, pages 80\u2013108, 2005.\u00a0\u21a9</p> </li> </ol>"},{"location":"user-guide/numerics/","title":"Numerical stability and edge cases","text":"<p>Weak-IV robust inference relies on projections, quadratic forms, and test inversion. This page summarizes the numerical choices in ivrobust.</p>"},{"location":"user-guide/numerics/#residualization-and-rank-deficiency","title":"Residualization and rank deficiency","text":"<ul> <li>Projections use QR/SVD-based routines to avoid explicit matrix inversion.</li> <li>Near-collinearity in instruments or controls can lead to rank-deficient   matrices; ivrobust falls back to pseudo-inverses and emits warnings where   possible.</li> </ul>"},{"location":"user-guide/numerics/#confidence-set-inversion","title":"Confidence set inversion","text":"<p>Confidence sets are computed by evaluating p-values on a grid and inverting the acceptance region:</p> <pre><code>{ beta : p(beta) &gt;= alpha }\n</code></pre> <p>Key numerical choices:</p> <ul> <li>Deterministic grid spacing (reproducible).</li> <li>Bracketing and refinement near acceptance boundaries.</li> <li>Explicit handling of unbounded or empty regions.</li> </ul>"},{"location":"user-guide/numerics/#nonstandard-set-shapes","title":"Nonstandard set shapes","text":"<p>Under weak identification, confidence sets may be:</p> <ul> <li>Empty.</li> <li>Unbounded (the real line).</li> <li>A union of disjoint intervals.</li> </ul> <p>These shapes are expected and should be reported without trimming.</p>"},{"location":"user-guide/numerics/#reproducibility-rules","title":"Reproducibility rules","text":"<ul> <li>Use fixed seeds in synthetic examples.</li> <li>Save plots with <code>ivr.savefig</code> to deterministic paths.</li> <li>Keep grid definitions explicit when comparing across methods.</li> </ul>"},{"location":"user-guide/plotting/","title":"Plotting","text":"<p>ivrobust uses a single, package-wide plotting style. It is intentionally conservative:</p> <ul> <li>White background</li> <li>Grayscale defaults</li> <li>Black edges and spines</li> <li>No seaborn styling</li> <li>Vector-friendly saving (PDF) plus high-DPI PNG</li> </ul>"},{"location":"user-guide/plotting/#style-entrypoint","title":"Style entrypoint","text":"<pre><code>import ivrobust as ivr\nivr.set_style()\n</code></pre> <p>The same settings are also available as a Matplotlib style file:</p> <pre><code>import matplotlib.pyplot as plt\nplt.style.use(\"docs-src/assets/ivrobust.mplstyle\")\n</code></pre> <p>Saving figures:</p> <pre><code>paths = ivr.savefig(fig, \"artifacts/figures/example\", formats=(\"png\", \"pdf\"))\npaths\n</code></pre>"},{"location":"user-guide/plotting/#weak-iv-p-value-curves","title":"Weak-IV p-value curves","text":"<pre><code>res = ivr.weakiv_inference(\n    data,\n    beta0=beta_true,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n    return_grid=True,\n)\nfig, ax = res.plot()\n</code></pre>"},{"location":"user-guide/workflow/","title":"Practitioner workflow: estimate -&gt; test -&gt; confidence set","text":"<p>This is the recommended sequence for weak-IV robust analysis.</p>"},{"location":"user-guide/workflow/#1-prepare-data","title":"1) Prepare data","text":"<pre><code>import ivrobust as ivr\n\ndata = ivr.IVData.from_arrays(\n    y=y,\n    d=d,\n    z=z,\n    x=x,          # include controls if needed\n    add_const=True,\n)\n</code></pre>"},{"location":"user-guide/workflow/#2-report-diagnostics","title":"2) Report diagnostics","text":"<pre><code>diag = ivr.weak_id_diagnostics(data, cov_type=\"HC1\")\ndiag.effective_f, diag.first_stage_f\n</code></pre>"},{"location":"user-guide/workflow/#3-run-weak-iv-robust-tests","title":"3) Run weak-IV robust tests","text":"<pre><code>res = ivr.weakiv_inference(\n    data,\n    beta0=0.0,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n)\nres.tests[\"AR\"].pvalue\n</code></pre>"},{"location":"user-guide/workflow/#4-report-confidence-sets","title":"4) Report confidence sets","text":"<pre><code>cs = res.confidence_sets[\"AR\"]\ncs.intervals\n</code></pre> <p>Intervals may be disjoint or unbounded under weak identification. Report the full union of intervals.</p>"},{"location":"user-guide/workflow/#5-visualize-p-value-curves-optional","title":"5) Visualize p-value curves (optional)","text":"<pre><code>res_grid = ivr.weakiv_inference(\n    data,\n    beta0=0.0,\n    alpha=0.05,\n    methods=(\"AR\", \"LM\", \"CLR\"),\n    cov_type=\"HC1\",\n    grid=(-2.0, 2.0, 301),\n    return_grid=True,\n)\nfig, ax = res_grid.plot()\n</code></pre>"},{"location":"user-guide/workflow/#6-pair-with-point-estimates-optional","title":"6) Pair with point estimates (optional)","text":"<pre><code>tsls = ivr.tsls(data, cov_type=\"HC1\")\ntsls.beta, tsls.stderr[-1, 0]\n</code></pre> <p>Point estimates are useful for reporting but are not weak-IV robust. Always present weak-IV robust tests and confidence sets when identification is weak.</p>"}]}